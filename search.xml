<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>No.6 WGAN+WGAN-GP</title>
      <link href="/2022/06/25/nineblog/"/>
      <url>/2022/06/25/nineblog/</url>
      
        <content type="html"><![CDATA[<h1 id="NO-6-WGAN-WGAN-GP"><a href="#NO-6-WGAN-WGAN-GP" class="headerlink" title="NO.6 WGAN+WGAN-GP"></a>NO.6 WGAN+WGAN-GP</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote><p>本节主要介绍WGAN与WGAN-GP，这两个模型创新点是从概率分布及其散度的视角来分析GAN，目的是解决GAN训练困难的问题，比如梯度消失与上一节CGAN也存在的mode collapse的问题，当然我们也可以从这个角度，比如研究概率散度的问题，构造GAN的新形式。</p></blockquote><h2 id="与GAN的区别"><a href="#与GAN的区别" class="headerlink" title="与GAN的区别"></a>与GAN的区别</h2><p>这篇文章主要解决了GAN的两个问题，一个是梯度消失，一个是mode collapse，文章中罗列了很多数学公式去介绍为什么GAN会存在这些问题（我表示我很难都读懂，所以我也就不介绍了。。）。我们可以知道的是GAN采用的是JS和KL散度评价分布距离，VAE采用的KL散度，而WGAN的创新点是引入了Wasserstein距离，又叫Earth-Mover（EM）推土机距离，它的优点是即使两个分布没有任何重叠，也可以反应他们之间的距离，因为JS散度对于分布没有重叠或者重叠较小的情况，它的值一直是log2，这就是Wasserstein距离可以解决GAN存在的问题关键所在，定义如下：</p><div align="center"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fimage.bubuko.com%2Finfo%2F201903%2F20190306224541339231.png&amp;refer=http%3A%2F%2Fimage.bubuko.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1659512854&amp;t=09697776fc07fac99de5b3d794d7e593"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 Wasserstein距离</div></div><p>WGAN-GP是对WGAN的进一步改进，GP的含义是gradient penalty，为什么要做gradient penalty呢？原因是WGAN在处理Lipschitz限制条件时，直接采用了weight clipping，这句话太过专业，简单来说，当我们更新参数时，WGAN会将所有参数限制到某一个阈值范围内，比如-0.1到0.1之间，而Loss函数又希望把真假图片的分布尽可能拉大，所以有可能参数最后的取值都是-0.1或者0.1，实验也验证了这种猜测，如图2所示。</p><div align="center"><img src="https://img-blog.csdnimg.cn/img_convert/796d0deef67b6a76ffab8131fd3df83f.png"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 Weight clipping</div></div><p>此外WGAN的另一个问题是会存在梯度消失或者梯度爆炸的问题，这也取决于weight clipping中设置的weigth的大小。<br>因此WGAN-GP针对这两个问题，在损失函数计算时做了改进，增加了一个额外的loss实现梯度与weight进行联系。改进后的目标函数如图3所示，</p><div align="center"><img src="https://img-blog.csdnimg.cn/img_convert/f399f1cd73a5d7a931ed8f5eadabfa3e.png"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 WGAN-GP目标函数</div></div><p>WGAN、WGAN-GP与GAN的区别，主要是损失函数与优化方式中，模型结构除了WGAN的判别器最后一层去掉了sigmoid，WGAN-GP的判别去掉了batch normalization（去掉的原因是bach norm会引入同个batch中不同样本的依赖关系），其他没有太大的变化，具体变化如下：</p><h3 id="LOSS"><a href="#LOSS" class="headerlink" title="LOSS"></a>LOSS</h3><p>WGAN判别器Loss计算方式，采用的是Wasserstein距离，并增加了weigt clipping的代码，具体实现代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss_D <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>fake_imgs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># weight clipping</span><span class="token keyword">for</span> p <span class="token keyword">in</span> discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    p<span class="token punctuation">.</span>data<span class="token punctuation">.</span>clamp_<span class="token punctuation">(</span><span class="token operator">-</span>opt<span class="token punctuation">.</span>clip_value<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>clip_value<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>WGAN生成器Loss实现代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">gen_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">)</span>loss_G <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>WGAN-GP判别器Loss加入了gradient_penalty，计算方式：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">real_validity <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span>fake_validity <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>fake_imgs<span class="token punctuation">)</span>gradient_penalty <span class="token operator">=</span> compute_gradient_penalty<span class="token punctuation">(</span>discriminator<span class="token punctuation">,</span>real_imgs<span class="token punctuation">.</span>data<span class="token punctuation">,</span>fake_imgs<span class="token punctuation">.</span>data<span class="token punctuation">)</span>loss_D <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>real<span class="token punctuation">.</span>validity<span class="token punctuation">)</span><span class="token operator">+</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>fakke_validity<span class="token punctuation">)</span><span class="token operator">+</span>lambda_gp<span class="token operator">*</span>gradient_penalty<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>WGAN-GP生成器Loss计算方式与WGAN是一样的，主要改变的是判别器，所以我们在看一下代码是如何实现gradient_penalty：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">compute_gradient_penalty</span><span class="token punctuation">(</span>D<span class="token punctuation">,</span>real_samples<span class="token punctuation">,</span>fake_samples<span class="token punctuation">)</span><span class="token punctuation">:</span>    alpha <span class="token operator">=</span> Tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span>real_samples<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    interpolates <span class="token operator">=</span> <span class="token punctuation">(</span>alpha<span class="token operator">*</span>real_samples<span class="token operator">+</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>alpha<span class="token punctuation">)</span><span class="token operator">*</span>fake_samples<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>    d_interpolates <span class="token operator">=</span> D<span class="token punctuation">(</span>interpolates<span class="token punctuation">)</span>    fake <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>real_samples<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    gradients <span class="token operator">=</span> autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>        outputs<span class="token operator">=</span>d_interpolates<span class="token punctuation">,</span>        inputs<span class="token operator">=</span>interpolates<span class="token punctuation">,</span>        grad_outputs<span class="token operator">=</span>fake<span class="token punctuation">,</span>        create_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        retain_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        only_inputs<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    gradients <span class="token operator">=</span> gradients<span class="token punctuation">.</span>view<span class="token punctuation">(</span>gradients<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    gradient_penalty <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>gradients<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>maen<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> gradient_penalty<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="优化方式"><a href="#优化方式" class="headerlink" title="优化方式"></a>优化方式</h3><p>相较于GAN，WGAN采用的是RMS，WGAN-GP依然采用的是Adam优化方式，但增加了对gradient_penalty的优化，实现方式如下：<br>WGAN：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">optimizer_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>generator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">)</span>optimizer_D <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>WGAN-GP:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">optimizer_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>generator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span>betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span>optimizer_D <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span>betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span>optimizer_info <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>     itertools<span class="token punctuation">.</span>chain<span class="token punctuation">(</span>generator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span>betas<span class="token operator">=</span>        <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="判别器的模型结构"><a href="#判别器的模型结构" class="headerlink" title="判别器的模型结构"></a>判别器的模型结构</h3><p>WGAN与WGAN-GP的判别器模型结构都是在最后一层删除了sigmoid()，我在这就没有贴代码。</p><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p>数据集采用的是MSTER数据集，WGAN部分效果如图所示：</p><div align="center"><img src="https://wx2.sinaimg.cn/mw2000/006b3B1mly1h3h2fjcchzj31i80wku0x.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图4 WGAN-Epoch 0</div></div><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2fmax39j31i80wkhdt.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图5 WGAN-Epoch 2000</div></div><div align="center"><img src="https://wx4.sinaimg.cn/mw2000/006b3B1mly1h3h2fplf40j31i80wknpd.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图6 WGAN-Epoch 5000</div></div><div align="center"><img src="https://wx4.sinaimg.cn/mw2000/006b3B1mly1h3h2fr5qj2j31i80wknpd.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图7 WGAN-Epoch 10000</div></div><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上是关于WGAN与WGAN-GP的介绍，我们从代码的角度与GAN进行了对比，总体来说，主要创新点有以下几点：<br>1、判别器与生成器的Loss计算方式引入了Wasserstein距离。<br>2、WGAN-GP在WGAN的基础上增加了Gradient Penalty。<br>3、优化方式以及模型结构做了部分修改。</p><h4 id="以上是GAN的第六节关于WGAN与WGAN-GP的讨论，主要介绍了在GAN的基础上有哪些改进，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是GAN的第六节关于WGAN与WGAN-GP的讨论，主要介绍了在GAN的基础上有哪些改进，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是GAN的第六节关于WGAN与WGAN-GP的讨论，主要介绍了在GAN的基础上有哪些改进，如有错误，欢迎指出，谢谢您！！！"></a>以上是GAN的第六节关于WGAN与WGAN-GP的讨论，主要介绍了在GAN的基础上有哪些改进，如有错误，欢迎指出，谢谢您！！！</h4>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> python </tag>
            
            <tag> WGAN </tag>
            
            <tag> WGAN-GP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>No.5 CGAN</title>
      <link href="/2022/06/18/eighblog/"/>
      <url>/2022/06/18/eighblog/</url>
      
        <content type="html"><![CDATA[<h1 id="NO-5-CGAN"><a href="#NO-5-CGAN" class="headerlink" title="NO.5 CGAN"></a>NO.5 CGAN</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote><p>本节主要介绍CGAN（条件生成对抗网络），该网络是在GAN的基础上，加入了条件信息，如果条件信息为类别标签，那CGAN就是将无监督的GAN变成了有监督的数据生成网络，这也是CGAN的最大创新点。</p></blockquote><h2 id="与GAN的区别"><a href="#与GAN的区别" class="headerlink" title="与GAN的区别"></a>与GAN的区别</h2><p>无论是GAN还是DCGAN等等这些网络，都是无监督的，简单来说数据生成的结果都是乱序的，但如果我们想生成某一标签的图像（比如飞机，汽车），这些网络都是做不到，因此CGAN应运而生，CGAN网络的生成结果都是有序的，而且你可以随意指定输出结果。与GAN的区别，主要是在生成器与判别的输入中，模型结构和损失函数都没有太大的变化，具体变化如下</p><h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><p>无论是判别器还是生成器，变化的主要是输入，我们可以对比分析以下，如何将labels这个向量与图像向量结合的，首先下面是GAN的G的代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token keyword">def</span> <span class="token function">block</span><span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>           layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">)</span><span class="token punctuation">]</span>           <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>               layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>out_feat<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           <span class="token keyword">return</span> layers       self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment"># Concatenate label embedding and image to produce input</span>       img <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>z<span class="token punctuation">)</span>       img <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>img_shape<span class="token punctuation">)</span>       <span class="token keyword">return</span> img<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于CGAN，生成器模型代码如下图所示，主要变化有两个，第一个是模型中加了label_embedding和第一层加入了classes，目的是为了维度统一；第二的变化是最重要的，在forward()函数中使用torch.cat()将随机噪声与标签向量合并，所以一般的label标签都是onehot形式。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>       self<span class="token punctuation">.</span>label_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>n_classes<span class="token punctuation">,</span>n_classes<span class="token punctuation">)</span>       <span class="token keyword">def</span> <span class="token function">block</span><span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>           layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">)</span><span class="token punctuation">]</span>           <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>               layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>out_feat<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           <span class="token keyword">return</span> layers       self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span>latent_dim <span class="token operator">+</span> n_classes<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> noise<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment"># Concatenate label embedding and image to produce input</span>       gen_input <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>label_emb<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">,</span> noise<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>       img <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>gen_input<span class="token punctuation">)</span>       img <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>img_shape<span class="token punctuation">)</span>       <span class="token keyword">return</span> img<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h3><p>原始GAN的判别器模型代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>       self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>       <span class="token punctuation">)</span>   <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment"># Concatenate label embedding and image to produce input</span>       d_in <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>       validity <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>d_in<span class="token punctuation">)</span>       <span class="token keyword">return</span> validity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>CGAN判别器的实现代码如下，变化的部分还是有两个，第一个与生成器类似，第二个也同样是采用torch.cat()函数将labels与影像结合。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>       self<span class="token punctuation">.</span>label_embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>n_classes<span class="token punctuation">,</span>n_classes<span class="token punctuation">)</span>       self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_classes <span class="token operator">+</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>       <span class="token punctuation">)</span>   <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment"># Concatenate label embedding and image to produce input</span>       d_in <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>label_embedding<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>       validity <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>d_in<span class="token punctuation">)</span>       <span class="token keyword">return</span> validity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><p>除了以上生成器与判别器模型的变化外，因为增加了标签向量，所以在计算loss时也需要增加，但没改变的是仍然采用的是MSELoss计算方法，CGAN的生成器计算Loss的代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 噪声和标签作为输入</span>       z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>FloatTensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>latent_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>       gen_labels <span class="token operator">=</span> Variable<span class="token punctuation">(</span>LongTensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>n_classes<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>       <span class="token comment"># 生成器产生图片</span>       gen_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">,</span> gen_labels<span class="token punctuation">)</span>       <span class="token comment"># 计算损失</span>       validity <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">,</span> gen_labels<span class="token punctuation">)</span>       g_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>validity<span class="token punctuation">,</span> valid<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>判别器依然需要计算真图与假图的Loss两者之和，所以实现代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 真实图片的损失</span>       validity_real <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>       d_real_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>validity_real<span class="token punctuation">,</span> valid<span class="token punctuation">)</span>       <span class="token comment"># 生成图片的损失</span>       validity_fake <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> gen_labels<span class="token punctuation">)</span>       d_fake_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>validity_fake<span class="token punctuation">,</span> fake<span class="token punctuation">)</span>       <span class="token comment"># 总损失</span>       d_loss <span class="token operator">=</span> <span class="token punctuation">(</span>d_real_loss <span class="token operator">+</span> d_fake_loss<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p>数据集采用的是MSTER数据集，以下是一些效果图，从图中可以看出来的是我们每一列的结果都是有序的，但是Epoch越大，结果会趋向于一个值，主要的原因是我们的数据集太少，其次是GAN存在的模式崩塌model collapse的问题，这一点我们在第一节中也提到过。</p><div align="center"><img src="https://wx1.sinaimg.cn/orj360/006b3B1mly1h3lgi9k2vbj3106106e81.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 Epoch 0</div></div><br><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3lgi9ulrbj3106106npd.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 Epoch 400</div></div><br><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3lgia68rkj3106106npd.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 Epoch 20000</div></div><br><br><div align="center"><img src="https://wx1.sinaimg.cn/mw2000/006b3B1mly1h3lgiamfjvj3106106kjl.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图4 Epoch 30000</div></div><br><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上是关于CGAN的介绍，因为DCGAN的改进主要是输入，所以我们主要从代码的角度与GAN进行了对比，总体来说，主要创新点有以下几点：<br>1、判别器与生成器在模型输入中采用torch.cat()函数将影像或噪声与标签进行了连接。<br>2、Loss计算时，将labels的loss也加入其中。<br>3、由效果图可以看出，最后的生成图像是按顺序排列的，当然也可以指定某一个标签进行生成。</p><h4 id="以上是GAN的第五节关于CGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是GAN的第五节关于CGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是GAN的第五节关于CGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！"></a>以上是GAN的第五节关于CGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！</h4>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> CGAN </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>No.4 DCGAN</title>
      <link href="/2022/06/11/seveblog/"/>
      <url>/2022/06/11/seveblog/</url>
      
        <content type="html"><![CDATA[<h1 id="NO-4-DCGAN"><a href="#NO-4-DCGAN" class="headerlink" title="NO.4 DCGAN"></a>NO.4 DCGAN</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote><p>本节主要介绍DCGAN（深度卷积生成对抗网络），该网络是在GAN的基础上，加入了卷积模块。2016年，Alec等人发表的论文《UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS》（简称DCGAN），首次提出将CNN模块应用到GAN模型中，从而代替全连接层。</p></blockquote><h2 id="与GAN的区别"><a href="#与GAN的区别" class="headerlink" title="与GAN的区别"></a>与GAN的区别</h2><p>GAN的原理大多都是一样的，没有再重复，DCGAN主要从网络结构上改进了GAN，下面我们将从代码中讨论DCGAN有哪些创新点。</p><h3 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h3><p>首先是DCGAN的G和D采用的卷积模块，替代了GAN的全连接层，但对于G和D也有一定的区别，首先下面是GAN的D的代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        img_flat <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        validity <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>img_flat<span class="token punctuation">)</span>        <span class="token keyword">return</span> validity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 判别器基本保留了卷积模块的组成，依然采用的是LeakyReLU激活函数，只不过是将原来的全连接层Linear换成了Conv2d层，代码如下:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">def</span> <span class="token function">discriminator_block</span><span class="token punctuation">(</span>in_filters<span class="token punctuation">,</span> out_filters<span class="token punctuation">,</span> bn<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            block <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_filters<span class="token punctuation">,</span> out_filters<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token keyword">if</span> bn<span class="token punctuation">:</span>                block<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_filters<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">return</span> block  self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>      <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>channels<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> bn<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><p>GAN的生成器采用的是Linear层与BatchNorml的组合，激活函数仍然是LeakyRelu，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">block</span><span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>           layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">)</span><span class="token punctuation">]</span>           <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>               layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>out_feat<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           <span class="token keyword">return</span> layers       self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于DCGAN，生成器G采用的是反卷积层，采用反卷积的目的就是可以将输入的随机噪声生成固定大小的向量（卷积的目的是将一个4<em>4变为2</em>2，反卷积就是将2<em>2变为4</em>4），因此反卷积是一个上采样的过程，实现生成器的方法有两种，一个是采用ConvTranspose2d，直接实现反卷积，另一种是采用上采样＋卷积的方式，在此给出两种实现反卷积的方式。下面代码是ConvTranspose2d方法，我们可以看到每一个卷积模块都是采用的是ConvTranspose2d+BatchNorm2d+ReLU，但这种方法如果卷积核为奇数时，会出现棋盘状的结果，所以对于kernel_size设置是一个关键：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">layer<span class="token operator">=</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channel<span class="token punctuation">,</span>self<span class="token punctuation">.</span>out_channel<span class="token punctuation">,</span>kernel_size<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span>padding<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>stride<span class="token operator">=</span>stride<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                   nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out_channel<span class="token punctuation">)</span><span class="token punctuation">,</span>                   nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>                   <span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>下面代码是采用的上采样＋卷积的方式实现反卷积，模块主要是上采样+Conv2d卷积+BatchNorm2d+LeakyReLU的方式：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>conv_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>           <span class="token comment">#nn.sequential{}是一个组成模型的壳子，用来容纳不同的操作</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token comment"># BatchNorm2d</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token comment">#上采样</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment">#二维卷积函数</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token comment">#relu激活函数</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token comment">#上采样</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#二维卷积</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token comment">#BN</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> opt<span class="token punctuation">.</span>channels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                              <span class="token comment">#Tanh激活函数</span>        <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="效果展示"><a href="#效果展示" class="headerlink" title="效果展示"></a>效果展示</h2><p>简单列出来了DCGAN的效果展示图（训练集采用的是MSTAR）：</p><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2ek8iboj30sy0ei12e.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 Epoch 0</div></div><br><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2ekmr0ej30sy0ein6d.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 Epoch 400</div></div><br><div align="center"><img src="https://wx1.sinaimg.cn/mw2000/006b3B1mly1h3h2el0kl6j30sy0ei12g.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 Epoch 800</div></div><br><br><div align="center"><img src="https://wx4.sinaimg.cn/mw2000/006b3B1mly1h3h2elfa0ej30sy0eitj3.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图4 Epoch 1000</div></div><br><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上是关于DCGAN的介绍，因为DCGAN的改进主要是网络结构，所以我们主要从代码的角度与GAN进行了对比，总体来说，主要创新点有以下几点：<br>1、判别器采用的是卷积，生成器采用的是反卷积，此外卷积模块都没有加入池化层。<br>2、加入了BN层，可加速模型训练<br>3、另外就是激活函数的区别，采用的是Relu与LeakyReLU，在生成器中最后一层采用的是Tanh，可以让模型更快学习。</p><h4 id="以上是GAN的第四节关于DCGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是GAN的第四节关于DCGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是GAN的第四节关于DCGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！"></a>以上是GAN的第四节关于DCGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！</h4>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> python </tag>
            
            <tag> DCGAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NO.1 GAN的基础知识</title>
      <link href="/2022/06/05/fourblog/"/>
      <url>/2022/06/05/fourblog/</url>
      
        <content type="html"><![CDATA[<h1 id="GAN是啥？"><a href="#GAN是啥？" class="headerlink" title="GAN是啥？"></a>GAN是啥？</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p><b>定义</b></p><blockquote><p>通俗的说，GAN是用来生成以假乱真的图像，在遥感领域的应用就是扩充我们的样本，可以解决两个问题：一是样本缺少（生成特定类型的影像），另一个是样本缺失（有些影像可能受云遮挡）。</p></blockquote><p><b>GAN的组成</b></p><blockquote><p>GAN相当于是由两个网络组成，一个是生成网络，一个是判别网络，生成网络相当于生产员，是用来将输入的随机噪声（原材料）生成一幅图像X（产品），判别网络相当于质检员，是将真实图像Y（产品标准）与生成图像X作比较，给出图像X是真还是假，通过她的判断，网络会不断优化，直至我们生成的图像（产品）接近于真实图像（接近于产品标准）。</p></blockquote><h2 id="用处"><a href="#用处" class="headerlink" title="用处"></a>用处</h2><p>GAN应用领域非常之广，不乏图像生成，图像转换（卫星图像→谷歌地图、给图像加滤镜、换脸、换衣服、素描→彩色图片），图像超分辨（修复一些比较老的影视剧）以及图像修复等等，但我学习的只涉及到图像生成领域，所以关于GAN的介绍也仅仅局限于图像生成。</p><p>GAN 在图像生成上的应用又可分为以下几种：图像合成、文本到图像、图像到图像、视频。图像生成是研究最多的，并且该领域的研究已经证明了在图像合成中使用 GAN 的巨大潜力。</p><h2 id="GAN发展"><a href="#GAN发展" class="headerlink" title="GAN发展"></a>GAN发展</h2><p>GAN如此之优秀，值得我们去探究了解她的发展。下面主要是对GAN经典模型的介绍，其他模型也大多是基于这些经典模型的改进。</p><p>2014年Goodfellow等人提出了GAN模型，原理如图1所示。之后Conditional GAN（CGAN）被Mizra等人提出，该模型将标签引入到网络中，使得生成的图像可以按标签的顺序罗列，解决了传统GAN生成顺序混乱的问题，原理如图2所示。</p><div align="center"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-76a6a1d99af14b6785434af91cb77014_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1657697403&amp;t=359fbd3690280aef59550b9a3823347c"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 GAN基本框架</div></div><br><div align="center"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fwww.icode9.com%2Fi%2Fll%2F%3Fi%3D20210306153717338.png%3F%2Ctype_ZmFuZ3poZW5naGVpdGk%2Cshadow_10%2Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3OTM3ODQ3%2Csize_16%2Ccolor_FFFFFF%2Ct_70%23pic_center&amp;refer=http%3A%2F%2Fwww.icode9.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1657697365&amp;t=f4ce77837538c79656071de725512abf"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 CGAN基本框架</div></div><p>2016年Radford提出了DCGAN，将深度卷积模块引入到GAN中，提高了GAN网络生成模型的性能，从此卷积模块也成为了GAN网络的优化方式之一。在这一年InfoGAN也被提出，这篇文章主要加入了隐含向量，可解释隐含向量是改变字体的大小粗细和倾斜度。<br><br></p><div align="center"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fs1.ax1x.com%2F2020%2F06%2F04%2FtB3BAf.md.png&amp;refer=http%3A%2F%2Fs1.ax1x.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1657697476&amp;t=3d4f1ae0e5826d29d832c52bdc0402d6"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 DCGAN基本框架</div></div><br>2017年Pix2pix被Isola提出，一个以CGAN为基础，用于图像翻译（Image Translation）的通用框架，它实现了模型结构和损失函数的通用化,CycleGAN与其类似，它与DiscoGAN、DualGAN网络结构也完全类似。之后WGAN（Wasserstein GAN）被提出，传统的GAN的使用的是KL散度或JS散度计算真假图像分布，所存在的问题是mode collapse，通俗的讲就是epoch越大，生成的图像会趋于某一个分布，而将Wasserstein距离的优势是计算两个分布的最小代价。随之WGAN-GP问世，该模型将gradient penalty (GP)引入，主要解决WGAN模型建模能力弱化，以及梯度爆炸或消失的问题。当然，在今年也提出了用的较多的GAN模型评价函数FID（Fréchet Inception 距离）。<p>从2018年起，GAN更加多样化，比较有代表性的比如StarGAN，它是将一个域的图像转换为目标域的多种图像，并支持多个目标域，简单说就是将原图像变换样式/风格style。例如，可根据人的性别设置图像域domain，在这种情况下，风格样式包括妆容类别、胡须和发型等。但这些基本上仍然是基于InfoGAN的思路，加入更多的隐含向量。</p><p>2019年BigGAN,StyleGAN在图像生成领域应用还比较多，BigGAN顾名思义，就是大，体现在在训练中 Batch 采用了很大的 Batch，已经达到了 2048，在卷积的通道上也是变大了，还有就是网络的参数变多了，据计算，在 2048 的 Batch 下整个网络的参数达到了接近 16 亿。StyleGAN是一种无监督式的自动学习方法，她对图像的高层语义属性做一定解耦分离，例如人脸图像的姿势和身份、所生成图像的随机变化如雀斑和头发等，但是，这些所解析的特征向量并不固定，也存在有些特征向量无法解释的问题。</p><p>2020年各大顶刊的文章对于GAN的变型数不胜数，主要基于了不同的需求，比如PSGAN将妆容和姿势进行风格变换，还引入了注意力机制。MISC针对多种背景的、多条件人像合成，提出了MISC，用于条件图像生成和图像组合。对于条件图像生成，利用条件间相关性来改进现有的条件注入机制condition injection mechanisms。</p><p>2021年与2022年的文章也更多，比如文本转图像，改进注意力机制，将transformer加入到GAN中，但总体GAN模型框架并没有太大的改变。在此不再罗列模型名称（PS：每个人的模型名称都是千差万别，实在是怪我没有能力全记住，哈哈哈）</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上就是GAN按时间顺序的发展历程，各有优缺点，也适应着各种不同的领域，总的来说，有网络结构的改进，比如加入标签、隐含向量、注意力、VAE等等；还有损失函数的优化，比如KL、JS、wasserstein距离等等。这就使得GAN可以做有监督的图像生成也可以做无监督的图像生成，我们需要根据不同的需求去测试不同网络的效果。从下一节开始，我们将逐一介绍以上经典网络，以及如何实现。</p><h3 id="以上是GAN一些基础知识，由于我了解也不够深入，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是GAN一些基础知识，由于我了解也不够深入，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是GAN一些基础知识，由于我了解也不够深入，如有错误，欢迎指出，谢谢您！！！"></a>以上是GAN一些基础知识，由于我了解也不够深入，如有错误，欢迎指出，谢谢您！！！</h3>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>No.3 FID环境搭建</title>
      <link href="/2022/06/05/fifthblog/"/>
      <url>/2022/06/05/fifthblog/</url>
      
        <content type="html"><![CDATA[<h1 id="NO-3-FID环境搭建遇到的问题"><a href="#NO-3-FID环境搭建遇到的问题" class="headerlink" title="NO.3 FID环境搭建遇到的问题"></a>NO.3 FID环境搭建遇到的问题</h1><h2 id="参数默认值设置"><a href="#参数默认值设置" class="headerlink" title="参数默认值设置"></a>参数默认值设置</h2><p>加载参数时出现了下面这个错误，错误原因是”path”参数是必须的</p><blockquote><p>usage: fid_score.py [-h] [–batch-size BATCH_SIZE] [–num-workers NUM_WORKERS] [–device DEVICE]<br>                    [–dims {64,192,768,2048}]<br>                    path path<br>fid_score.py: error: the following arguments are required: path<br>An exception has occurred, use %tb to see the full traceback.</p></blockquote><p><b> 解决方法：</b><br>虽然代码中存在”path”参数，但需要在”path”加上”–”,才可以设置该参数的默认值</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--path'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> nargs<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>default<span class="token operator">=</span><span class="token string">"./data/"</span><span class="token punctuation">,</span>                    <span class="token builtin">help</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'Paths to the generated images or '</span>                          <span class="token string">'to .npz statistic files'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="没有属性sched-getaffinity"><a href="#没有属性sched-getaffinity" class="headerlink" title="没有属性sched_getaffinity"></a>没有属性sched_getaffinity</h2><p>OS模块没有sched_getaffinity属性，具体报错信息：</p><blockquote><p>AttributeError: module ‘os’ has no attribute ‘sched_getaffinity’</p></blockquote><p>os.sched_getaffinity()Python中的method方法用于获取可在其上运行具有指定进程ID的进程的CPU组<br>此方法仅在某些LIUNX平台上可用。</p><p><b> 解决方法：</b></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">num_workers <span class="token operator">=</span> <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="CUDA错误：no-kernel-image"><a href="#CUDA错误：no-kernel-image" class="headerlink" title="CUDA错误：no kernel image"></a>CUDA错误：no kernel image</h2><p>具体错误信息：</p><blockquote><p>CUDA error: no kernel image is available for execution on the device</p></blockquote><p>这个错误网上主要有两种解决办法，</p><ol><li>GPU与CUDA版本不兼容<br><b> 解决方法：</b><br>CUDA官网查看，python、cuda、torch的对应版本情况<br>下面这个链接可以直接查看版本对应号，找到之后，去重新安装正确的版本<br><a href="https://blog.csdn.net/weixin_45564943/article/details/121688734">https://blog.csdn.net/weixin_45564943/article/details/121688734</a></li><li>电脑配置不行<br>重新换个配置高的电脑</li><li>编译器的问题<br>以上两种方法都没有解决我的问题，实在没有找到解决方法，因为这个问题是在spyder中报的错，所以就尝试将spyder换成了pycharm，运行之后，发现没有报错，具体为什么，我也搞不明白。。。</li></ol><p><b> 补充: </b></p><ol><li><p>如果你的问题是第一种，但你可能无法下载指定版本的torch,这时需要你自己编译torch，所以下面这个博主帮大家解决了如何编译Pytorch源码的问题<br><a href="https://blog.csdn.net/qq_43051923/article/details/108393510">https://blog.csdn.net/qq_43051923/article/details/108393510</a></p></li><li><p>如何查Windows下的CUDA版本？<br> <a href="https://blog.csdn.net/qq_40447251/article/details/95861447">https://blog.csdn.net/qq_40447251/article/details/95861447</a></p></li></ol><h3 id="以上是我计算FID搭建环境时遇到的问题，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是我计算FID搭建环境时遇到的问题，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是我计算FID搭建环境时遇到的问题，如有错误，欢迎指出，谢谢您！！！"></a>以上是我计算FID搭建环境时遇到的问题，如有错误，欢迎指出，谢谢您！！！</h3>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> python </tag>
            
            <tag> FID </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>No.2 GAN的实现</title>
      <link href="/2022/05/31/sixblog/"/>
      <url>/2022/05/31/sixblog/</url>
      
        <content type="html"><![CDATA[<h1 id="NO-2-GAN的实现"><a href="#NO-2-GAN的实现" class="headerlink" title="NO.2 GAN的实现"></a>NO.2 GAN的实现</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote><p>这是GAN相关内容的第二节介绍，考虑到大多数的资料可能原理是原理，代码是代码，我希望我写的东西，可以将代码与原理尽量一一对应，因为当我们明白代码是如何实现这些数学理论后，我们就可以去改进、完善模型。<br>但介绍原理我并不擅长，只能利用我薄弱的数学基础，以我能理解的方式去介绍，所以难免可能会有错误，如果你有幸看到我这篇文章又很费心碰巧发现了错误，恳请批评指正~</p></blockquote><p>为了将原理与代码对应，我们主要分两部分介绍：前向传播与后向传播。在GAN中前向传播包括了生成网络与判别网络两部分，后向传播是损失函数。</p><h2 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h2><p> 初始化，随机产生一组变量，此时初始化的G与D没有任何作用。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">valid <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>随机生成一组分布z，将z输入到G得到一组假图（fake images）即x’ = G(z)，在整个图像生成中，G并没有输入真实图片x，它也不在乎真实图片x长什么样，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#随机噪声</span>gen_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">)</span>    <span class="token comment">#生成器生成fake图像</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>取一组图片x，输入到判别器计算D(x)，对于判别器会接收真实图像，也会接收G生成的fake图，接收真图代码如下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">real_imgs <span class="token operator">=</span> Variable<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">)</span>discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span>    <span class="token comment">#判别器</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>以上generator与discriminator即为GAN搭建的网络模型，代码在最后给出。</p><h2 id="后向传播"><a href="#后向传播" class="headerlink" title="后向传播"></a>后向传播</h2><p>因为判别器D与生成器G是两个不同的网络模型，所以是分别计算loss值后进行反向传播。对于G，它的目标是让D误以为x’是真实图片，因此G的损失函数可以是D(x’)和1之间的差距，这个差距越小，表明在D看来x’越真实。按照loss减小的方向，调整G的每一个参数，便完成了G的一次优化。我们需要固定判别器优化生成器，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">g_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>  <span class="token comment">#计算loss</span>g_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#反向传播</span>optimizer_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#优化参数</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>对于D，损失函数包括两方面：第一是真图计算的D(x)应当比较大，例如和1尽可能接近；第二是fake图x’对应的D(x’)应当比较小，例如和0尽可能接近。同理以loss函数减小的方向，调整D的每一个参数实现对D优化。我们需要固定生成器优化判别器，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">real_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>fake_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fake<span class="token punctuation">)</span>d_loss <span class="token operator">=</span> <span class="token punctuation">(</span>real_loss <span class="token operator">+</span> fake_loss<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>d_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer_D<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ok,G和D的优化都用到了adversarial_loss，那这个loss代码如何实现的呢？</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">adversarial_loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其实就是使用了BCELoss（交叉熵），然后BCELoss的公式如下图</p><div align="center"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fwww.pianshen.com%2Fimages%2F127%2F0dbe652bb1b3227e59e62749290e6a57.png&amp;refer=http%3A%2F%2Fwww.pianshen.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1657812535&amp;t=d85047d914af232e2bf8823350ebce27"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 BCElOSS</div></div><br><p>ok,而论文给的loss计算公式如下，发现与BCELoss的公式还是有差别的，发现第一项少了BCE公式的后半部分，第二项少了BCE公式的前半部分。注意第一项的E x ∼ p r ( x ) E的下标表示x来自真实样本，所以在BCE公式的yn = 1，所以BCE公式的后半部分为0，第二项同理也为0，我们也可以看到代码中D也是分别求了两个Loss值。至于生成器的公式同理，在此也没有再赘述。</p><div align="center"><img src="https://img-blog.csdnimg.cn/20191213145817665.png"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 原文中的Loss计算公式</div></div><br><h2 id="网络模型代码"><a href="#网络模型代码" class="headerlink" title="网络模型代码"></a>网络模型代码</h2><p>前向传播我们没有具体给出G与D的模型代码，在此我们给出模型代码与训练优化的实现代码，但是在此没有给出如何加载数据集的程序，后面我们会介绍如何用torch构建无标签和有标签的数据集：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Generator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">block</span><span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>                layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>out_feat<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> layers        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>        img <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        img <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>img_shape<span class="token punctuation">)</span>        <span class="token keyword">return</span> img<span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        img_flat <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        validity <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>img_flat<span class="token punctuation">)</span>        <span class="token keyword">return</span> validity<span class="token comment"># Loss function</span>adversarial_loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># Initialize generator and discriminator</span>generator <span class="token operator">=</span> Generator<span class="token punctuation">(</span><span class="token punctuation">)</span>discriminator <span class="token operator">=</span> Discriminator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> cuda<span class="token punctuation">:</span>    generator<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    discriminator<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    adversarial_loss<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># Configure data loader</span>img_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    <span class="token comment"># transforms.ToPILImage(),</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># (x-mean) / std</span><span class="token punctuation">]</span><span class="token punctuation">)</span>optimizer_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>generator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span>optimizer_D <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span>Tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>FloatTensor <span class="token keyword">if</span> cuda <span class="token keyword">else</span> torch<span class="token punctuation">.</span>FloatTensor <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> img <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>            imgs <span class="token operator">=</span> img                        valid <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>            fake <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>            <span class="token comment"># Configure input</span>            real_imgs <span class="token operator">=</span> Variable<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment"># -----------------</span>            <span class="token comment">#  Train Generator</span>            <span class="token comment"># -----------------</span>            optimizer_G<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># Sample noise as generator input</span>            z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment"># Generate a batch of images</span>            gen_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">)</span>            <span class="token comment"># Loss measures generator's ability to fool the discriminator</span>            g_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>            g_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># ---------------------</span>            <span class="token comment">#  Train Discriminator</span>            <span class="token comment"># ---------------------</span>            optimizer_D<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># Measure discriminator's ability to classify real from generated samples</span>            real_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>            fake_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fake<span class="token punctuation">)</span>            d_loss <span class="token operator">=</span> <span class="token punctuation">(</span>real_loss <span class="token operator">+</span> fake_loss<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>            d_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer_D<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>                <span class="token string">"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"</span>                <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>n_epochs<span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> d_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> g_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token punctuation">)</span>            batches_done <span class="token operator">=</span> epoch <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span> <span class="token operator">+</span> i            <span class="token keyword">if</span> <span class="token punctuation">(</span>batches_done <span class="token operator">%</span> opt<span class="token punctuation">.</span>sample_interval <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> epoch <span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                save_image<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> savename<span class="token operator">+</span>save_filename<span class="token operator">+</span><span class="token string">'_'</span><span class="token operator">+</span><span class="token string">"%d.png"</span> <span class="token operator">%</span> batches_done<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="以上是GAN的第二节介绍，主要介绍了原理与实现，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是GAN的第二节介绍，主要介绍了原理与实现，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是GAN的第二节介绍，主要介绍了原理与实现，如有错误，欢迎指出，谢谢您！！！"></a>以上是GAN的第二节介绍，主要介绍了原理与实现，如有错误，欢迎指出，谢谢您！！！</h3>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python 爬虫</title>
      <link href="/2022/05/28/thirblog/"/>
      <url>/2022/05/28/thirblog/</url>
      
        <content type="html"><![CDATA[<h1 id="用python从mou网页中简单抓取mou信息"><a href="#用python从mou网页中简单抓取mou信息" class="headerlink" title="用python从mou网页中简单抓取mou信息"></a>用python从mou网页中简单抓取mou信息</h1><blockquote><p>爬虫并不专业，但写这篇是因为昨天蒋总提到爬虫，担心离职前没时间交流这个事，所以先写个blog，以防万一哪天你（您）又问我了，我不在公司咋整？（后半句纯粹为自己写这篇找的理由，哈哈哈 ）</p></blockquote><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>某知名襄阳富二代小朱想了解一下竞争对手，网站上发布了考试信息，我们准备帮他找一下和他考一个专业的学生有多少个，考试名单如下：</p><br><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2psh6l8j30wv0o446u.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 需要爬虫的信息</div></div><br><!--<div align="center"><img src="./thirblog/1.png"/></div>--><h2 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h2><p>打开cmd运行如下命令，安装两个包requests、bs4</p><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">pip install requestspip install bs4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果使用pip安装bs4报错，可以采用本地安装方式：</p><p>1、下载bs4包到本地并解压（记住路径）：<a href="https://www.crummy.com/software/BeautifulSoup/bs4/download/">https://www.crummy.com/software/BeautifulSoup/bs4/download/</a><br>2、用cmd定位到下载的bs4包：beautifulsoup4-4.11.1</p><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">cd E:\Program Files (x86)\beautifulsoup4-4.11.1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3、本地安装bs4，使用命令：</p><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">python setup.py install<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="爬取网页内容"><a href="#爬取网页内容" class="headerlink" title="爬取网页内容"></a>爬取网页内容</h2><p>ok，准备工作完成，爬取网页信息：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">url <span class="token operator">=</span> <span class="token string">'http://jw.hbuas.edu.cn/info/1061/2393.htm'</span>  <span class="token comment">#网址</span>response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>  <span class="token comment"># 获取该网址的信息</span>response<span class="token punctuation">.</span>encoding<span class="token operator">=</span>response<span class="token punctuation">.</span>apparent_encoding  <span class="token comment">#这一步是判断网页的解码格式，因为网页的编码方式不同</span>html <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">,</span><span class="token string">'lxml'</span><span class="token punctuation">)</span> <span class="token comment">#使用lxml解析器，对网页信息进行解析</span>content<span class="token operator">=</span>html<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#vsb_content &gt; div &gt; div &gt; div'</span><span class="token punctuation">)</span><span class="token comment">#将复制好的选择器信息放进select方法中，将获取到的内容作为tag形式放入一个列表中</span><span class="token comment">#这一步很关键，取决你的网页形式，需要F12打开网页源码，去查看你想要的内容在哪个div下</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果打印的结果不是0，说明已经成功抓取你想要的信息</p><h2 id="保存结果"><a href="#保存结果" class="headerlink" title="保存结果"></a>保存结果</h2><p>我们将抓取的信息保存到了txt文档中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">filename <span class="token operator">=</span> <span class="token string">"1.txt"</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"1.txt"</span><span class="token punctuation">,</span><span class="token string">"w"</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">:</span>    s <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>content<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>s<span class="token punctuation">)</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"保存文件成功"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们抓取的信息如下：</p><br><div align="center"><img src="https://wx2.sinaimg.cn/mw2000/006b3B1mly1h3h2psld3yj30ly0hhjtl.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 爬虫结果</div></div><br><!--<div align="center"><img src="./thirblog/2.png"/></div>--><h2 id="整理结果"><a href="#整理结果" class="headerlink" title="整理结果"></a>整理结果</h2><br><div align="center"><img src="https://wx1.sinaimg.cn/mw2000/006b3B1mly1h3h2pssdr6j30n30atn55.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 统计结果</div></div><br><!--<div align="center"><img src="./thirblog/3.png"/></div>--><p>在EXCEL打开后，我们看到有315个学生考地理科学专业，听小朱说招90多个，离考试还有二十多天，在此也默默祝福小朱金榜题名！！！</p><p>最后，我用jieba对这组数据尝试做了词云分析，这些数据也很有趣，但我没做详细分析，比如考生涉及的城市武汉，襄阳较多；除汉族考生外回族考生也不少；<br>考生姓氏张、刘等较多；报考旅游、地理科学、学前教育、机械等专业考生较多，或许是该校优势专业，等等。。。</p><br><div align="center"><img src="https://wx4.sinaimg.cn/mw2000/006b3B1mly1h3h2pszm52j311i0ku11a.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图4 词云分析</div></div><br><!--<div align="center"><img src="./thirblog/4.png"/></div>--><h4 id="简单的一个从网页抓取信息的例子就完成了，如有错误，欢迎指出，谢谢您！！！"><a href="#简单的一个从网页抓取信息的例子就完成了，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="简单的一个从网页抓取信息的例子就完成了，如有错误，欢迎指出，谢谢您！！！"></a>简单的一个从网页抓取信息的例子就完成了，如有错误，欢迎指出，谢谢您！！！</h4>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo部署</title>
      <link href="/2022/05/22/secblog/"/>
      <url>/2022/05/22/secblog/</url>
      
        <content type="html"><![CDATA[<h1 id="hexo部署"><a href="#hexo部署" class="headerlink" title="hexo部署"></a>hexo部署</h1><blockquote><p>上一篇解决了hexo安装的问题，这一篇简单介绍如何进行hexo搭建一个简单博客</p></blockquote><h2 id="下载主题"><a href="#下载主题" class="headerlink" title="下载主题"></a>下载主题</h2><p>hexo官方主题下载地址：<a href="https://hexo.io/themes/">https://hexo.io/themes/</a><br>这里面挑选适合的主题，比如下载下面这个主题：<a href="https://github.com/JoeyBling/hexo-theme-yilia-plus">https://github.com/JoeyBling/hexo-theme-yilia-plus</a><br>在根目录下，右键鼠标打开bash<br><br></p><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2p9okqrj30ko0b70td.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 hexo打开</div></div><br><!--![](./secblog/bash.png)--><p>运行如下命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token builtin class-name">cd</span> theme$ <span class="token function">git</span> clone --depth<span class="token operator">=</span><span class="token number">1</span> https://github.com/JoeyBling/hexo-theme-yilia-plus.git ./yilia-plus<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>修改hexo根目录下的 _config.yml中，修改theme: yilia-plus</p><h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2><p>运行如下命令</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token builtin class-name">cd</span> themes/yilia-plus$ <span class="token function">git</span> pull<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="配置config"><a href="#配置config" class="headerlink" title="配置config"></a>配置config</h2><p>在_config.yml中配置自己喜欢的样式即可，github可以查看每个主题的config的内容，不再赘述。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>同样在根目录下打开bash，运行如下命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo clean$ hexo generate$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>当然部署会遇到一些问题。比如： Failed to connect to github.com port 443: Timed out</p><br><div align="center"><img src="https://wx1.sinaimg.cn/mw2000/006b3B1mly1h3h2p9rw0lj30jo073wjt.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 部署问题</div></div><br><!--![](./secblog/hexod.png)--><p>出现这种问题很正常，这是本地部署，会存在网络的问题，可以打开（关闭）翻墙软件，多次尝试部署，成功部署会显示：</p><br><div align="center"><img src="https://wx2.sinaimg.cn/mw2000/006b3B1mly1h3h2p9w66tj30k706jn2s.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 上传成功</div></div><br><!--![](./secblog/hexosuc.png)--><p>如果这种问题一直未能解决，可以选择Hexo Github Action、vercel 部署等方式。</p><h3 id="以上是部署hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是部署hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是部署hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！"></a>以上是部署hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！</h3>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo安装问题</title>
      <link href="/2022/05/16/firstblog/"/>
      <url>/2022/05/16/firstblog/</url>
      
        <content type="html"><![CDATA[<h1 id="Windows下使用npm安装hexo报错"><a href="#Windows下使用npm安装hexo报错" class="headerlink" title="Windows下使用npm安装hexo报错"></a>Windows下使用npm安装hexo报错</h1><blockquote><p>本篇共解决三个问题：ERR；npm update； hexo command not found</p></blockquote><h2 id="ERR错误"><a href="#ERR错误" class="headerlink" title="ERR错误"></a>ERR错误</h2><p>在安装npm时，遇到第一个问题是一连串的ERR错误，网上主要有两种解决方法，如果you遇到同样问题，可以先尝试如下</p><p><b> 解决方法：</b></p><ul><li>删除C:\Users{user}下的.npmrc文件</li><li>运行命令：<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">npm</span> cache clean –force<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>但我尝试两种方法后，安装npm，仍然还存在以下问题：</li></ul><br><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2oljl6yj30pv0d1k90.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 ERR错误</div></div><br><!-- ![](./firstblog/hexo1.png)--><p><b> 解决方法：</b></p><p>搞了好久，检查之后，发现是打开了翻墙软件，所以这个报错有可能是pip打不开需要访问的地址。关掉后，问题解决！！！但又出现下一个问题。</p><h2 id="npm更新问题"><a href="#npm更新问题" class="headerlink" title="npm更新问题"></a>npm更新问题</h2><!-- ![](./firstblog/hexo2.png)--><br><div align="center"><img src="https://wx2.sinaimg.cn/mw2000/006b3B1mly1h3h2olppxbj30ju07ggpt.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 npm更新</div></div><br><p>提示Run npm install -g <a href="mailto:npm@8.10.0">npm@8.10.0</a> to update<br>运行命令，对npm先升级，再安装hexo</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">npm</span> <span class="token function">install</span> -g <span class="token function">npm</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="hexo已安装，但找不到该命令"><a href="#hexo已安装，但找不到该命令" class="headerlink" title="hexo已安装，但找不到该命令"></a>hexo已安装，但找不到该命令</h2><p>运行hexo -v查看安装版本时，又出现hexo不是内部命令，或者出现“bash: hexo: command not found”提示</p><!-- <div align="center"><img src="./firstblog/hexo3.png"/></div>--><br><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2oltd0oj30d302e3zc.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 hexo命令</div></div><br><p><b> 解决方法：</b><br>找到 C:\Users\Administrator\AppData\Roaming\npm\node_modules\hexo\bin\，将此目录添加到path环境变量中<br>重新打开命令窗口，成功。</p><!-- <div align="center"><img src="./firstblog/hexo4.png"/></div>--><br><div align="center"><img src="https://wx4.sinaimg.cn/mw2000/006b3B1mly1h3h2oly5hyj306l08ygnz.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图4 hexo成功安装</div></div><br><h3 id="以上是我安装hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是我安装hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是我安装hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！"></a>以上是我安装hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！</h3>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> npm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/05/12/hello-world/"/>
      <url>/2022/05/12/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
