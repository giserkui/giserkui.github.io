<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Thanks</title>
      <link href="/2022/07/23/tweblog/"/>
      <url>/2022/07/23/tweblog/</url>
      
        <content type="html"><![CDATA[<h1 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h1><p>实习的最后一篇了，文采不好，就写篇流水账了</p><p>先说说自己为啥想写既不实用又没啥技术含量的网页吧。初心就是想记录自己在这段时光中遇到的人做过的事，如果哪一天我想你们了，总比翻照片快吧，又或哪一天我患了阿尔兹海默症，这几篇文章这几张图片还能唤醒自己这一段美好的记忆，我就把这段时间做过的东西，拍过的照片，想说的话保存在了这里。</p><p>昨天部门团建，让我回想到了第一天来公司参加的团建，那时可能还不到十人，昨天已经二十多人了，时间过的快，人换的也勤，这也是人生常态，能一直在你身边的又有几个。四个多月的实习经历很充实，认识的每一个人也让我倍加珍惜，虽然对每个人我没有真正了解，但让我能回忆到的大家还都有特色，充满着真诚的爱意。对于我个人而言，我尽量回忆我认识大家的顺序，或许有误。。。：</p><p>静姐，是个新晋宝妈，做过公益讼诉的一些工作，工作努力细致，之前觉得很无聊的工作，让我认识到了每一项工作的重要性与技巧性，也愿您孩子健康快乐长大</p><p>艳姐，我愿称之为公司最漂亮的人，相比之下，打扮更时尚，说话也很温柔，有幸一起吃饭遛弯，也让我知道了有钱很难买到的是气质</p><p>赵博士，是个狠人，我是觉得是个很严肃的人，或许是因为自己担心工作干不好会被说吧，但并没有，反而相处很开心，给我感觉他一直在工位上忙个不停，blog记录的大部分都是他教我的，当然，还有一些，可惜我没时间整理了，但确实教我了很多</p><p>蒋总，是个女强者，乐观饱含热情，一起吃饭，一起熬夜加班的日子，让我认识到了在北京生活该努力的样子，还常常和我女朋友谈起她的努力和幸福家庭，确实影响了我很多</p><p>刘总，是成功人士，虽说聊的不多，是一个讲诚信的领导，有一次车上随口说了一句有机会聊聊您的经历，没想到他真的找了个时间，给我讲了很多</p><p>岩哥，是个成熟的男孩子，有幸成为岩哥同桌，没想到是同龄，看起来我显得更不成熟，祝岩哥赶快恢复，篮球场需要你</p><p>杨哥，是个实在人，年龄虽大一些，但经验多，在长春安排住宿请吃饭，哈哈，以后一定再找机会请回来</p><p>张总，是个接梗王，和张总一起，永远缺不了梗，也就缺不了欢声笑语</p><p>金豆，是个值得交的朋友，真实又认真，做事迅速，每次打招呼都会笑，和我一样，也有些不自信，或许是我们的这个年龄段的通病，空有一腔热血，但总觉得自己能力还不够</p><p>通哥，是个金主家的孩子，无忧无虑的生活，待人真诚，虽不怎么和人交流，但每次开完会都默默收拾椅子，看得出来他还是自己暗自努力，通过自己的方式融入集体</p><p>因为有聚会，我第一天认识了十几个人</p><p>朱哥，是个男孩子，自信又擅于辩论，和蒋总一样爱笑，爱干净审美不错，好吧，都是我永远无法做到的，希望他未来依旧，努力学习，让自己内心更加强大</p><p>汪总，是个面带善意的总裁，一次汪总参加了部门聚会，有幸敬过酒，每次公司碰见，也是很平易近人，没有总裁架子</p><p>强总，是个笑面虎领导，有幸一起参加过一次公司培训，强总还总是回答问题，提出疑惑，是个很爱学又有技术的领导，看得出来对这行的热爱</p><p>文颖，是个文静的女孩子，但是我大哥，心有灵犀，有次蒋总聚会睡在沙发，我把防晒衣递给了文颖，没有说话没有眼神交流，她就拿给蒋总盖了，不愧是兄弟，懂</p><p>黄哥，是个果断的人，有幸听黄哥说，之前是在事业单位，因为兴趣以及不甘于稳定，决心辞掉来北京闯荡，愿我有朝一日做事有黄哥这种勇气</p><p>峰哥，是个高富帅，听闻峰哥给老爸买了辆车，有联想到峰哥的经历，是个孝顺的孩子，而对于我来说，又是多么羡慕峰哥有这种机会呢，如今的我仍然对自己充满悔恨</p><p>斌哥，是个勤奋的人，没记错入职第一天就在加班，后面和斌哥一起干活，看得出来对待每一件事的认真，程序改了又改，非要达到最准确的效果</p><p>旭哥，是个强者，能力毋庸置疑，同龄的我自愧不如，一次问了旭哥问题，但旭哥第二天又微信给我解释，如此真诚帮助我，值得交</p><p>韩总，是个局气人，说话办事，谈吐举止，语言中带着和蔼</p><p>龙哥，是个暖男，有幸去过长春，虽时间不长，龙哥还开车带我去医院做核酸，听闻龙哥母亲当时还在医院，也祝阿姨早日康复</p><p>丹丹姐，是个王者，我们三个唯一上过王者的，是有毅力的女孩子，也期待以后一起带我飞</p><p>函哥，是校友，不仅是校友，连函哥的同学都是我专业课老师，有幸听过函哥一次培训，看到他沉浸在自己的系统中，或许这才是兴趣</p><p>说到校友，还有李总，是我师姐，同处一个办公区，她安排人员能力，对待工作的逻辑思维，有目共睹</p><p>还有吴哥，打过篮球的健存总，谢总，nlp的强哥，龙哥，离职的隋博士，晓坤，，，</p><p>好吧，当然还有很多很多，如果继续写可能要写到深夜了，写文档有个坏毛病，不愿意去检查，要是写错啥了，也别见怪了。</p><p>记录自己认识的每一个人，很开心认识到你们，一声感谢，一声祝好，一声有缘再会</p>]]></content>
      
      
      <categories>
          
          <category> thanks </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thanks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>No.7 InfoGAN</title>
      <link href="/2022/07/09/eleblog/"/>
      <url>/2022/07/09/eleblog/</url>
      
        <content type="html"><![CDATA[<h1 id="NO-7-InfoGAN"><a href="#NO-7-InfoGAN" class="headerlink" title="NO.7 InfoGAN"></a>NO.7 InfoGAN</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote><p>本节主要介绍InfoGAN，前面五节我们提到的GAN输入是随机噪声，生成一张与原图非常相似的图像，那我们能不能控制影像的某一个特征，来生成我们所期望的图像。答案是肯定的，但是会非常复杂，因为一张图片通过GAN我们可以提取上百上千个特征，大部分特征是不可解释的。针对这个问题InfoGAN引入了特征解耦，控制某些特征变得清晰规律化。</p></blockquote><h2 id="与GAN的区别"><a href="#与GAN的区别" class="headerlink" title="与GAN的区别"></a>与GAN的区别</h2><p>InfoGAN实现了特征解耦，针对minist数据集，解耦出来的特征主要有两种，一个是控制数字生成的倾斜度，一个是控制数字生成的粗细，与GAN的最大区别是输入数据包括了随机噪声、标签和隐向量，标签用于生成有序的图像，隐向量控制了某一特征有规律的变化。在InfoGAN中可解释的隐向量有两个，其他特征也未能解释出来。针对SAR影像，特征空间与minist数据集还是有区别，噪声较多，效果还没达到minist数据集精度，但是我们也尝试将角度特征进行解耦，并生成了新角度的数据。首先我们还是以GAN为基础，结合代码与对原理进行介绍，在本篇的最后我们会附上效果图。</p><h3 id="隐向量C"><a href="#隐向量C" class="headerlink" title="隐向量C"></a>隐向量C</h3><p>隐向量控制着特征的输出，这是最主要的点，我们先看一下如何在代码中构建一个隐向量，并将其与噪声拼接。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">zeros <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>n_row <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>c_varied <span class="token operator">=</span> np<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span>n_row<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span><span class="token punctuation">,</span>n_row<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>c1 <span class="token operator">=</span> Variable<span class="token punctuation">(</span>FloatTensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>c_varied<span class="token punctuation">,</span>zeros<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>c2 <span class="token operator">=</span> Variable<span class="token punctuation">(</span>FloatTensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>zeros<span class="token punctuation">,</span>c_varied<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>sample1 <span class="token operator">=</span> generator<span class="token punctuation">(</span>static_z<span class="token punctuation">,</span>static_label<span class="token punctuation">,</span>c1<span class="token punctuation">)</span>sample2 <span class="token operator">=</span> generator<span class="token punctuation">(</span>static_z<span class="token punctuation">,</span>static_label<span class="token punctuation">,</span>c2<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Loss函数"><a href="#Loss函数" class="headerlink" title="Loss函数"></a>Loss函数</h3><p>因为加入了隐向量，所以Loss计算也有所改变，总体的目标函数在GAN的基础上加入了互信息变分正则化I，公式如下:</p><div align="center"><img src="https://img1.baidu.com/it/u=3503824322,1135442809&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=JPEG?w=664&amp;h=344"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 InfoGAN目标函数</div></div><p>在代码实现中，各个LOSS计算是分开的，首先是对生成器的优化，依然采用的是交叉熵损失函数，主要的变化是输入数据加入了隐向量C，具体代码实现如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>FloatTensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> label_input <span class="token operator">=</span> to_categorical<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>classes<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">,</span>num_columns<span class="token operator">=</span>classes<span class="token punctuation">)</span> code_input <span class="token operator">=</span> Variable<span class="token punctuation">(</span>FloatTensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>code_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> gen_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">,</span>label_input<span class="token punctuation">,</span>code_input<span class="token punctuation">)</span>validity<span class="token punctuation">,</span>_<span class="token punctuation">,</span>_ <span class="token operator">-</span> discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">)</span>g_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>validity<span class="token punctuation">,</span>valid<span class="token punctuation">)</span>g_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer_g<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其次是对判别器的训练优化，与GAN并没有什么变化，输入到判别器中的仍然是真实图像与fake图像，并取平均计算最终判别器的loss，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">real_pred<span class="token punctuation">,</span>_<span class="token punctuation">,</span>_ <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span>d_real_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>real_pred<span class="token punctuation">,</span>valid<span class="token punctuation">)</span>fake_pred<span class="token punctuation">,</span>_<span class="token punctuation">,</span>_ <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>d_fake_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>fake_pred<span class="token punctuation">,</span>fake<span class="token punctuation">)</span>d_loss <span class="token operator">=</span> <span class="token punctuation">(</span>d_real_loss<span class="token operator">+</span>d_fake_loss<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span> d_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer_D<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后是互信息的Loss，原文中该部分称为Q网络，与判别器网络不同的是，在上一模块判别器网络中，虽然将真实图像与Fake图像都输入到网络中，但是只经过了网络中的卷积模块；而Q网络虽然与判别器网络模型一致，但是它会经过两层的全连接层用于预测，具体优化的代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">sample_labels <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>classes<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span>gt_labels <span class="token operator">=</span> Variable<span class="token punctuation">(</span>LongTensor<span class="token punctuation">(</span>sample_labels<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>FloatTensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>label_input <span class="token operator">=</span> to_categorical<span class="token punctuation">(</span>sample_labels<span class="token punctuation">,</span>num_columns <span class="token operator">=</span> classes<span class="token punctuation">)</span>code_input <span class="token operator">=</span> Variable<span class="token punctuation">(</span>FloatTensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>code_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>gen_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">,</span>label_input<span class="token punctuation">,</span>code_input<span class="token punctuation">)</span>_<span class="token punctuation">,</span>pred_label<span class="token punctuation">,</span>pred_code <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">)</span>info_loss <span class="token operator">=</span> lambda_cat<span class="token operator">*</span>categorical_loss<span class="token punctuation">(</span>pred_label<span class="token punctuation">,</span>gt_labels<span class="token punctuation">)</span>_lambda_con<span class="token operator">*</span>continuous_loss<span class="token punctuation">(</span>pred_code<span class="token punctuation">,</span>code_input<span class="token punctuation">)</span>info_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer_info<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>adversarial_loss与continuous_loss采用的均方损失函数，categorical采用的是交叉熵损失函数，具体实现方式之间已经学习过了，所以在此不再过多介绍。</p><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p>在InfoGAN中，网络结构采用的是DCGAN（前面章节我们讲过），在这一部分，我们只给了判别器和Q网络的模型结构，因为上一部分提高D与Q网络会经过判别器的不同部分，所以可以学习如何实现同一个网络中，输入到不同的模块中。具体实现代码如下:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">discriminator_block</span><span class="token punctuation">(</span>in_filters<span class="token punctuation">,</span> out_filters<span class="token punctuation">,</span> bn<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token triple-quoted-string string">"""Returns layers of each discriminator block"""</span>            block <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_filters<span class="token punctuation">,</span> out_filters<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token keyword">if</span> bn<span class="token punctuation">:</span>                block<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_filters<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> block        self<span class="token punctuation">.</span>conv_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>channels<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> bn<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        <span class="token comment"># The height and width of downsampled image</span>        ds_size <span class="token operator">=</span> opt<span class="token punctuation">.</span>img_size <span class="token operator">//</span> <span class="token number">2</span> <span class="token operator">**</span> <span class="token number">4</span>        <span class="token comment"># Output layers</span>        self<span class="token punctuation">.</span>adv_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span> <span class="token operator">*</span> ds_size <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>aux_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span> <span class="token operator">*</span> ds_size <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> opt<span class="token punctuation">.</span>n_classes<span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>latent_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span> <span class="token operator">*</span> ds_size <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> opt<span class="token punctuation">.</span>code_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>       out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_blocks<span class="token punctuation">(</span>img<span class="token punctuation">)</span>       out <span class="token operator">=</span> out<span class="token punctuation">.</span>view<span class="token punctuation">(</span>out<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>       validity <span class="token operator">=</span> self<span class="token punctuation">.</span>adv_layer<span class="token punctuation">(</span>out<span class="token punctuation">)</span>       label <span class="token operator">=</span> self<span class="token punctuation">.</span>aux_layer<span class="token punctuation">(</span>out<span class="token punctuation">)</span>       latent_code <span class="token operator">=</span> self<span class="token punctuation">.</span>latent_layer<span class="token punctuation">(</span>out<span class="token punctuation">)</span>       <span class="token keyword">return</span> validity<span class="token punctuation">,</span> label<span class="token punctuation">,</span> latent_code<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p>数据集采用的是MSTER数据集，部分效果如图所示，每一列是控制角度特征生成的不同角度的数据，但这个还有很大的改进空间。</p><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3lgkxhywej3106106kjl.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 InfoGAN效果图</div></div><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上是关于InfoGAN的介绍，我们从代码的角度与GAN进行了对比，总体来说，主要创新点有以下几点：<br>1、因为引入了隐变量，所以对互信息部分进行优化，因此判别器、生成器与Q网络的Loss计算方式做了改进。<br>2、判别器与Q网络的模型结构使用上有了区别，判别器网络只会经过卷积模块。<br>3、重点是InfoGAN利用了特征解耦的原理，得到了可解释的特征，实现了不同角度，不同 大小等特征的数据生成。</p><h4 id="以上是GAN的第7节关于InfoGAN的讨论，仅仅是个人见解，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是GAN的第7节关于InfoGAN的讨论，仅仅是个人见解，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是GAN的第7节关于InfoGAN的讨论，仅仅是个人见解，如有错误，欢迎指出，谢谢您！！！"></a>以上是GAN的第7节关于InfoGAN的讨论，仅仅是个人见解，如有错误，欢迎指出，谢谢您！！！</h4>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> python </tag>
            
            <tag> InfoGAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch模型输入（tifF输入以及不同尺寸数据读入/保存）</title>
      <link href="/2022/07/02/tenblog/"/>
      <url>/2022/07/02/tenblog/</url>
      
        <content type="html"><![CDATA[<h1 id="pytorch模型输入（tif输入以及不同尺寸数据读入保存）"><a href="#pytorch模型输入（tif输入以及不同尺寸数据读入保存）" class="headerlink" title="pytorch模型输入（tif输入以及不同尺寸数据读入保存）"></a>pytorch模型输入（tif输入以及不同尺寸数据读入保存）</h1><blockquote><p>解决pytorch模型输入问题，主要包括两个问题，一个是16位的tiff输入问题，一个是长宽不一致时，数据如何处理，保存时如何进行图片裁剪的问题。</p></blockquote><h2 id="16位tiff数据的输入"><a href="#16位tiff数据的输入" class="headerlink" title="16位tiff数据的输入"></a>16位tiff数据的输入</h2><p>之前深度学习模型 的数据集大多是JPG或者PNG格式，如果是单波段，大多也都是8位的，对于16位的tif数据输入还是第一次碰到，pytorch可以支持8位图片读取，所以这个代码实现了16位图片的读入与保存，个人感觉还是挺有用。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>img_arr <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>img<span class="token punctuation">)</span>img_arr <span class="token operator">=</span> img_arr<span class="token operator">/</span><span class="token number">1</span><span class="token keyword">if</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">:</span>    img <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>img_arr<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但这个代码只能用于处理tif，如果JPG或者PNG，Loss值会很大，所以如果写这个代码需要加一个判断是否加载的数据为tif格式。</p><h2 id="长宽不一致时的数据读入"><a href="#长宽不一致时的数据读入" class="headerlink" title="长宽不一致时的数据读入"></a>长宽不一致时的数据读入</h2><p>因为项目需求，需要处理的图像可能会碰到长宽不一致的现象，以下代码思路是对其进行padding操作，还有滑窗的方式，在此就没有列出。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">padding_img</span><span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">:</span>    w<span class="token punctuation">,</span>h <span class="token operator">=</span> img<span class="token punctuation">.</span>size  <span class="token comment">#获取图像的长宽进行判断</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>w<span class="token operator">==</span>h<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> w    <span class="token keyword">elif</span> w<span class="token operator">&gt;</span>h<span class="token punctuation">:</span>        img_new <span class="token operator">=</span> Image<span class="token punctuation">.</span>new<span class="token punctuation">(</span>img<span class="token punctuation">.</span>mode<span class="token punctuation">,</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span>w<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment">#0表示背景色，也可以设置其他颜色</span>        img_new<span class="token punctuation">.</span>paste<span class="token punctuation">(</span>img<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">(</span>w<span class="token operator">-</span>h<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#//在这用的整除算式</span>        <span class="token keyword">return</span> img_new    <span class="token keyword">else</span><span class="token punctuation">:</span>        img_new <span class="token operator">=</span> Image<span class="token punctuation">.</span>new<span class="token punctuation">(</span>img<span class="token punctuation">.</span>mode<span class="token punctuation">,</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span>h<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment">#0表示背景色，也可以设置其他颜色</span>        img_new<span class="token punctuation">.</span>paste<span class="token punctuation">(</span>img<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token punctuation">(</span>h<span class="token operator">-</span>w<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#//在这用的整除算式</span>        <span class="token keyword">return</span> img_new<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="长宽不一致数据保存"><a href="#长宽不一致数据保存" class="headerlink" title="长宽不一致数据保存"></a>长宽不一致数据保存</h2><p>因为在前面数据输入的时候对数据进行了pandding处理，所以数据保存要对其裁剪，但这个裁剪确实是个坑，虽然只有简单几行代码，但也花了我至少半天时间，才开始我寻找了两种保存方式save_image()与img.write()，但这两种并不能改变图像的大小，所以我们要对预测结果的tensor处理，然后就尝试用resize()，crop()，clamp()，reshape()等函数处理，发现也不行，因为预测结果的tensor是含有梯度的，不能对其进行尺寸大小的改变，所以需要先将其转为numpy，然后numpy之后，resize()函数依然报错，所以直接用列表取值的方式将数据取出。取出之后采用save_image(保存又报错，是因为我们需要再把numpy转为tensor,具体代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">img_res <span class="token operator">=</span> img_gen<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>img_res1 <span class="token operator">=</span> img_res<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>img_fin <span class="token operator">=</span> imgres1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">(</span>w<span class="token operator">-</span>h<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>height<span class="token operator">+</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">(</span>w<span class="token operator">-</span>h<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span>width<span class="token punctuation">]</span>img_save <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>img_fin<span class="token punctuation">)</span>save_image<span class="token punctuation">(</span>img_save<span class="token punctuation">.</span>data<span class="token punctuation">,</span><span class="token string">"save.tif"</span><span class="token punctuation">,</span>nrow<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>normalize<span class="token operator">=</span>true<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面代码还有个坑，是用列表取数据时，前两维也需要写，含义是波段与batch_size。因为padiding我们是对图像的两侧分别填充，所以截取数据的时候下标需要注意，上面代码只列出了宽度大于高度的情况。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>写这篇博客主要觉得自己以前跑的数据集都是公开的，大多格式都一样，如果在项目中，数据会有各种问题，所以想记录一下，这个还挺有共性的一个解决方案。其实上面保存在我今天整理问题的时候还有个问题，采用列表方式取数据时，有的时候长宽与原图片一致，有的时候竟然颠倒，好吧，如果你也遇到，欢迎多多指教。好吧，就写这么多了，希望明天能解决上个问题。</p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> python </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>No.6 WGAN+WGAN-GP</title>
      <link href="/2022/06/25/nineblog/"/>
      <url>/2022/06/25/nineblog/</url>
      
        <content type="html"><![CDATA[<h1 id="NO-6-WGAN-WGAN-GP"><a href="#NO-6-WGAN-WGAN-GP" class="headerlink" title="NO.6 WGAN+WGAN-GP"></a>NO.6 WGAN+WGAN-GP</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote><p>本节主要介绍WGAN与WGAN-GP，这两个模型创新点是从概率分布及其散度的视角来分析GAN，目的是解决GAN训练困难的问题，比如梯度消失与上一节CGAN也存在的mode collapse的问题，当然我们也可以从这个角度，比如研究概率散度的问题，构造GAN的新形式。</p></blockquote><h2 id="与GAN的区别"><a href="#与GAN的区别" class="headerlink" title="与GAN的区别"></a>与GAN的区别</h2><p>这篇文章主要解决了GAN的两个问题，一个是梯度消失，一个是mode collapse，文章中罗列了很多数学公式去介绍为什么GAN会存在这些问题（我表示我很难都读懂，所以我也就不介绍了。。）。我们可以知道的是GAN采用的是JS和KL散度评价分布距离，VAE采用的KL散度，而WGAN的创新点是引入了Wasserstein距离，又叫Earth-Mover（EM）推土机距离，它的优点是即使两个分布没有任何重叠，也可以反应他们之间的距离，因为JS散度对于分布没有重叠或者重叠较小的情况，它的值一直是log2，这就是Wasserstein距离可以解决GAN存在的问题关键所在，定义如下：</p><div align="center"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fimage.bubuko.com%2Finfo%2F201903%2F20190306224541339231.png&amp;refer=http%3A%2F%2Fimage.bubuko.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1659512854&amp;t=09697776fc07fac99de5b3d794d7e593"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 Wasserstein距离</div></div><p>WGAN-GP是对WGAN的进一步改进，GP的含义是gradient penalty，为什么要做gradient penalty呢？原因是WGAN在处理Lipschitz限制条件时，直接采用了weight clipping，这句话太过专业，简单来说，当我们更新参数时，WGAN会将所有参数限制到某一个阈值范围内，比如-0.1到0.1之间，而Loss函数又希望把真假图片的分布尽可能拉大，所以有可能参数最后的取值都是-0.1或者0.1，实验也验证了这种猜测，如图2所示。</p><div align="center"><img src="https://img-blog.csdnimg.cn/img_convert/796d0deef67b6a76ffab8131fd3df83f.png"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 Weight clipping</div></div><p>此外WGAN的另一个问题是会存在梯度消失或者梯度爆炸的问题，这也取决于weight clipping中设置的weigth的大小。<br>因此WGAN-GP针对这两个问题，在损失函数计算时做了改进，增加了一个额外的loss实现梯度与weight进行联系。改进后的目标函数如图3所示，</p><div align="center"><img src="https://img-blog.csdnimg.cn/img_convert/f399f1cd73a5d7a931ed8f5eadabfa3e.png"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 WGAN-GP目标函数</div></div><p>WGAN、WGAN-GP与GAN的区别，主要是损失函数与优化方式中，模型结构除了WGAN的判别器最后一层去掉了sigmoid，WGAN-GP的判别去掉了batch normalization（去掉的原因是bach norm会引入同个batch中不同样本的依赖关系），其他没有太大的变化，具体变化如下：</p><h3 id="LOSS"><a href="#LOSS" class="headerlink" title="LOSS"></a>LOSS</h3><p>WGAN判别器Loss计算方式，采用的是Wasserstein距离，并增加了weigt clipping的代码，具体实现代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss_D <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>fake_imgs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># weight clipping</span><span class="token keyword">for</span> p <span class="token keyword">in</span> discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    p<span class="token punctuation">.</span>data<span class="token punctuation">.</span>clamp_<span class="token punctuation">(</span><span class="token operator">-</span>opt<span class="token punctuation">.</span>clip_value<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>clip_value<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>WGAN生成器Loss实现代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">gen_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">)</span>loss_G <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>WGAN-GP判别器Loss加入了gradient_penalty，计算方式：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">real_validity <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span>fake_validity <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>fake_imgs<span class="token punctuation">)</span>gradient_penalty <span class="token operator">=</span> compute_gradient_penalty<span class="token punctuation">(</span>discriminator<span class="token punctuation">,</span>real_imgs<span class="token punctuation">.</span>data<span class="token punctuation">,</span>fake_imgs<span class="token punctuation">.</span>data<span class="token punctuation">)</span>loss_D <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>real<span class="token punctuation">.</span>validity<span class="token punctuation">)</span><span class="token operator">+</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>fakke_validity<span class="token punctuation">)</span><span class="token operator">+</span>lambda_gp<span class="token operator">*</span>gradient_penalty<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>WGAN-GP生成器Loss计算方式与WGAN是一样的，主要改变的是判别器，所以我们在看一下代码是如何实现gradient_penalty：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">compute_gradient_penalty</span><span class="token punctuation">(</span>D<span class="token punctuation">,</span>real_samples<span class="token punctuation">,</span>fake_samples<span class="token punctuation">)</span><span class="token punctuation">:</span>    alpha <span class="token operator">=</span> Tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span>real_samples<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    interpolates <span class="token operator">=</span> <span class="token punctuation">(</span>alpha<span class="token operator">*</span>real_samples<span class="token operator">+</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>alpha<span class="token punctuation">)</span><span class="token operator">*</span>fake_samples<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>    d_interpolates <span class="token operator">=</span> D<span class="token punctuation">(</span>interpolates<span class="token punctuation">)</span>    fake <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>real_samples<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    gradients <span class="token operator">=</span> autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>        outputs<span class="token operator">=</span>d_interpolates<span class="token punctuation">,</span>        inputs<span class="token operator">=</span>interpolates<span class="token punctuation">,</span>        grad_outputs<span class="token operator">=</span>fake<span class="token punctuation">,</span>        create_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        retain_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        only_inputs<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    gradients <span class="token operator">=</span> gradients<span class="token punctuation">.</span>view<span class="token punctuation">(</span>gradients<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    gradient_penalty <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>gradients<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>maen<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> gradient_penalty<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="优化方式"><a href="#优化方式" class="headerlink" title="优化方式"></a>优化方式</h3><p>相较于GAN，WGAN采用的是RMS，WGAN-GP依然采用的是Adam优化方式，但增加了对gradient_penalty的优化，实现方式如下：<br>WGAN：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">optimizer_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>generator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">)</span>optimizer_D <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>WGAN-GP:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">optimizer_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>generator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span>betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span>optimizer_D <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span>betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span>optimizer_info <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>     itertools<span class="token punctuation">.</span>chain<span class="token punctuation">(</span>generator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span>betas<span class="token operator">=</span>        <span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="判别器的模型结构"><a href="#判别器的模型结构" class="headerlink" title="判别器的模型结构"></a>判别器的模型结构</h3><p>WGAN与WGAN-GP的判别器模型结构都是在最后一层删除了sigmoid()，我在这就没有贴代码。</p><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p>数据集采用的是MSTER数据集，WGAN部分效果如图所示：</p><div align="center"><img src="https://wx2.sinaimg.cn/mw2000/006b3B1mly1h3h2fjcchzj31i80wku0x.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图4 WGAN-Epoch 0</div></div><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2fmax39j31i80wkhdt.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图5 WGAN-Epoch 2000</div></div><div align="center"><img src="https://wx4.sinaimg.cn/mw2000/006b3B1mly1h3h2fplf40j31i80wknpd.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图6 WGAN-Epoch 5000</div></div><div align="center"><img src="https://wx4.sinaimg.cn/mw2000/006b3B1mly1h3h2fr5qj2j31i80wknpd.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图7 WGAN-Epoch 10000</div></div><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上是关于WGAN与WGAN-GP的介绍，我们从代码的角度与GAN进行了对比，总体来说，主要创新点有以下几点：<br>1、判别器与生成器的Loss计算方式引入了Wasserstein距离。<br>2、WGAN-GP在WGAN的基础上增加了Gradient Penalty。<br>3、优化方式以及模型结构做了部分修改。</p><h4 id="以上是GAN的第六节关于WGAN与WGAN-GP的讨论，主要介绍了在GAN的基础上有哪些改进，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是GAN的第六节关于WGAN与WGAN-GP的讨论，主要介绍了在GAN的基础上有哪些改进，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是GAN的第六节关于WGAN与WGAN-GP的讨论，主要介绍了在GAN的基础上有哪些改进，如有错误，欢迎指出，谢谢您！！！"></a>以上是GAN的第六节关于WGAN与WGAN-GP的讨论，主要介绍了在GAN的基础上有哪些改进，如有错误，欢迎指出，谢谢您！！！</h4>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> python </tag>
            
            <tag> WGAN </tag>
            
            <tag> WGAN-GP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>No.5 CGAN</title>
      <link href="/2022/06/18/eighblog/"/>
      <url>/2022/06/18/eighblog/</url>
      
        <content type="html"><![CDATA[<h1 id="NO-5-CGAN"><a href="#NO-5-CGAN" class="headerlink" title="NO.5 CGAN"></a>NO.5 CGAN</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote><p>本节主要介绍CGAN（条件生成对抗网络），该网络是在GAN的基础上，加入了条件信息，如果条件信息为类别标签，那CGAN就是将无监督的GAN变成了有监督的数据生成网络，这也是CGAN的最大创新点。</p></blockquote><h2 id="与GAN的区别"><a href="#与GAN的区别" class="headerlink" title="与GAN的区别"></a>与GAN的区别</h2><p>无论是GAN还是DCGAN等等这些网络，都是无监督的，简单来说数据生成的结果都是乱序的，但如果我们想生成某一标签的图像（比如飞机，汽车），这些网络都是做不到，因此CGAN应运而生，CGAN网络的生成结果都是有序的，而且你可以随意指定输出结果。与GAN的区别，主要是在生成器与判别的输入中，模型结构和损失函数都没有太大的变化，具体变化如下</p><h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><p>无论是判别器还是生成器，变化的主要是输入，我们可以对比分析以下，如何将labels这个向量与图像向量结合的，首先下面是GAN的G的代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token keyword">def</span> <span class="token function">block</span><span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>           layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">)</span><span class="token punctuation">]</span>           <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>               layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>out_feat<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           <span class="token keyword">return</span> layers       self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment"># Concatenate label embedding and image to produce input</span>       img <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>z<span class="token punctuation">)</span>       img <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>img_shape<span class="token punctuation">)</span>       <span class="token keyword">return</span> img<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于CGAN，生成器模型代码如下图所示，主要变化有两个，第一个是模型中加了label_embedding和第一层加入了classes，目的是为了维度统一；第二的变化是最重要的，在forward()函数中使用torch.cat()将随机噪声与标签向量合并，所以一般的label标签都是onehot形式。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>       self<span class="token punctuation">.</span>label_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>n_classes<span class="token punctuation">,</span>n_classes<span class="token punctuation">)</span>       <span class="token keyword">def</span> <span class="token function">block</span><span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>           layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">)</span><span class="token punctuation">]</span>           <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>               layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>out_feat<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           <span class="token keyword">return</span> layers       self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span>latent_dim <span class="token operator">+</span> n_classes<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> noise<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment"># Concatenate label embedding and image to produce input</span>       gen_input <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>label_emb<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">,</span> noise<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>       img <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>gen_input<span class="token punctuation">)</span>       img <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>img_shape<span class="token punctuation">)</span>       <span class="token keyword">return</span> img<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h3><p>原始GAN的判别器模型代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>       self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>       <span class="token punctuation">)</span>   <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment"># Concatenate label embedding and image to produce input</span>       d_in <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>       validity <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>d_in<span class="token punctuation">)</span>       <span class="token keyword">return</span> validity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>CGAN判别器的实现代码如下，变化的部分还是有两个，第一个与生成器类似，第二个也同样是采用torch.cat()函数将labels与影像结合。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>       self<span class="token punctuation">.</span>label_embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>n_classes<span class="token punctuation">,</span>n_classes<span class="token punctuation">)</span>       self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_classes <span class="token operator">+</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>       <span class="token punctuation">)</span>   <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment"># Concatenate label embedding and image to produce input</span>       d_in <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>label_embedding<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>       validity <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>d_in<span class="token punctuation">)</span>       <span class="token keyword">return</span> validity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><p>除了以上生成器与判别器模型的变化外，因为增加了标签向量，所以在计算loss时也需要增加，但没改变的是仍然采用的是MSELoss计算方法，CGAN的生成器计算Loss的代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 噪声和标签作为输入</span>       z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>FloatTensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>latent_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>       gen_labels <span class="token operator">=</span> Variable<span class="token punctuation">(</span>LongTensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>n_classes<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>       <span class="token comment"># 生成器产生图片</span>       gen_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">,</span> gen_labels<span class="token punctuation">)</span>       <span class="token comment"># 计算损失</span>       validity <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">,</span> gen_labels<span class="token punctuation">)</span>       g_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>validity<span class="token punctuation">,</span> valid<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>判别器依然需要计算真图与假图的Loss两者之和，所以实现代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 真实图片的损失</span>       validity_real <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>       d_real_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>validity_real<span class="token punctuation">,</span> valid<span class="token punctuation">)</span>       <span class="token comment"># 生成图片的损失</span>       validity_fake <span class="token operator">=</span> discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> gen_labels<span class="token punctuation">)</span>       d_fake_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>validity_fake<span class="token punctuation">,</span> fake<span class="token punctuation">)</span>       <span class="token comment"># 总损失</span>       d_loss <span class="token operator">=</span> <span class="token punctuation">(</span>d_real_loss <span class="token operator">+</span> d_fake_loss<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p>数据集采用的是MSTER数据集，以下是一些效果图，从图中可以看出来的是我们每一列的结果都是有序的，但是Epoch越大，结果会趋向于一个值，主要的原因是我们的数据集太少，其次是GAN存在的模式崩塌model collapse的问题，这一点我们在第一节中也提到过。</p><div align="center"><img src="https://wx1.sinaimg.cn/orj360/006b3B1mly1h3lgi9k2vbj3106106e81.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 Epoch 0</div></div><br><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3lgi9ulrbj3106106npd.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 Epoch 400</div></div><br><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3lgia68rkj3106106npd.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 Epoch 20000</div></div><br><br><div align="center"><img src="https://wx1.sinaimg.cn/mw2000/006b3B1mly1h3lgiamfjvj3106106kjl.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图4 Epoch 30000</div></div><br><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上是关于CGAN的介绍，因为DCGAN的改进主要是输入，所以我们主要从代码的角度与GAN进行了对比，总体来说，主要创新点有以下几点：<br>1、判别器与生成器在模型输入中采用torch.cat()函数将影像或噪声与标签进行了连接。<br>2、Loss计算时，将labels的loss也加入其中。<br>3、由效果图可以看出，最后的生成图像是按顺序排列的，当然也可以指定某一个标签进行生成。</p><h4 id="以上是GAN的第五节关于CGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是GAN的第五节关于CGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是GAN的第五节关于CGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！"></a>以上是GAN的第五节关于CGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！</h4>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> CGAN </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>No.4 DCGAN</title>
      <link href="/2022/06/11/seveblog/"/>
      <url>/2022/06/11/seveblog/</url>
      
        <content type="html"><![CDATA[<h1 id="NO-4-DCGAN"><a href="#NO-4-DCGAN" class="headerlink" title="NO.4 DCGAN"></a>NO.4 DCGAN</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote><p>本节主要介绍DCGAN（深度卷积生成对抗网络），该网络是在GAN的基础上，加入了卷积模块。2016年，Alec等人发表的论文《UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS》（简称DCGAN），首次提出将CNN模块应用到GAN模型中，从而代替全连接层。</p></blockquote><h2 id="与GAN的区别"><a href="#与GAN的区别" class="headerlink" title="与GAN的区别"></a>与GAN的区别</h2><p>GAN的原理大多都是一样的，没有再重复，DCGAN主要从网络结构上改进了GAN，下面我们将从代码中讨论DCGAN有哪些创新点。</p><h3 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h3><p>首先是DCGAN的G和D采用的卷积模块，替代了GAN的全连接层，但对于G和D也有一定的区别，首先下面是GAN的D的代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        img_flat <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        validity <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>img_flat<span class="token punctuation">)</span>        <span class="token keyword">return</span> validity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 判别器基本保留了卷积模块的组成，依然采用的是LeakyReLU激活函数，只不过是将原来的全连接层Linear换成了Conv2d层，代码如下:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">def</span> <span class="token function">discriminator_block</span><span class="token punctuation">(</span>in_filters<span class="token punctuation">,</span> out_filters<span class="token punctuation">,</span> bn<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            block <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_filters<span class="token punctuation">,</span> out_filters<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token keyword">if</span> bn<span class="token punctuation">:</span>                block<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_filters<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">return</span> block  self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>      <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>channels<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> bn<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><p>GAN的生成器采用的是Linear层与BatchNorml的组合，激活函数仍然是LeakyRelu，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">block</span><span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>           layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">)</span><span class="token punctuation">]</span>           <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>               layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>out_feat<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           <span class="token keyword">return</span> layers       self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于DCGAN，生成器G采用的是反卷积层，采用反卷积的目的就是可以将输入的随机噪声生成固定大小的向量（卷积的目的是将一个4<em>4变为2</em>2，反卷积就是将2<em>2变为4</em>4），因此反卷积是一个上采样的过程，实现生成器的方法有两种，一个是采用ConvTranspose2d，直接实现反卷积，另一种是采用上采样＋卷积的方式，在此给出两种实现反卷积的方式。下面代码是ConvTranspose2d方法，我们可以看到每一个卷积模块都是采用的是ConvTranspose2d+BatchNorm2d+ReLU，但这种方法如果卷积核为奇数时，会出现棋盘状的结果，所以对于kernel_size设置是一个关键：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">layer<span class="token operator">=</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channel<span class="token punctuation">,</span>self<span class="token punctuation">.</span>out_channel<span class="token punctuation">,</span>kernel_size<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span>padding<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>stride<span class="token operator">=</span>stride<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                   nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out_channel<span class="token punctuation">)</span><span class="token punctuation">,</span>                   nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>                   <span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>下面代码是采用的上采样＋卷积的方式实现反卷积，模块主要是上采样+Conv2d卷积+BatchNorm2d+LeakyReLU的方式：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>conv_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>           <span class="token comment">#nn.sequential{}是一个组成模型的壳子，用来容纳不同的操作</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token comment"># BatchNorm2d</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token comment">#上采样</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment">#二维卷积函数</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token comment">#relu激活函数</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token comment">#上采样</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#二维卷积</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token comment">#BN</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> opt<span class="token punctuation">.</span>channels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                              <span class="token comment">#Tanh激活函数</span>        <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="效果展示"><a href="#效果展示" class="headerlink" title="效果展示"></a>效果展示</h2><p>简单列出来了DCGAN的效果展示图（训练集采用的是MSTAR）：</p><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2ek8iboj30sy0ei12e.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 Epoch 0</div></div><br><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2ekmr0ej30sy0ein6d.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 Epoch 400</div></div><br><div align="center"><img src="https://wx1.sinaimg.cn/mw2000/006b3B1mly1h3h2el0kl6j30sy0ei12g.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 Epoch 800</div></div><br><br><div align="center"><img src="https://wx4.sinaimg.cn/mw2000/006b3B1mly1h3h2elfa0ej30sy0eitj3.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图4 Epoch 1000</div></div><br><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上是关于DCGAN的介绍，因为DCGAN的改进主要是网络结构，所以我们主要从代码的角度与GAN进行了对比，总体来说，主要创新点有以下几点：<br>1、判别器采用的是卷积，生成器采用的是反卷积，此外卷积模块都没有加入池化层。<br>2、加入了BN层，可加速模型训练<br>3、另外就是激活函数的区别，采用的是Relu与LeakyReLU，在生成器中最后一层采用的是Tanh，可以让模型更快学习。</p><h4 id="以上是GAN的第四节关于DCGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是GAN的第四节关于DCGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是GAN的第四节关于DCGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！"></a>以上是GAN的第四节关于DCGAN的讨论，主要介绍了创新点与在GAN的基础上有哪些改进的方法，如有错误，欢迎指出，谢谢您！！！</h4>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> python </tag>
            
            <tag> DCGAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NO.1 GAN的基础知识</title>
      <link href="/2022/06/05/fourblog/"/>
      <url>/2022/06/05/fourblog/</url>
      
        <content type="html"><![CDATA[<h1 id="GAN是啥？"><a href="#GAN是啥？" class="headerlink" title="GAN是啥？"></a>GAN是啥？</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p><b>定义</b></p><blockquote><p>通俗的说，GAN是用来生成以假乱真的图像，在遥感领域的应用就是扩充我们的样本，可以解决两个问题：一是样本缺少（生成特定类型的影像），另一个是样本缺失（有些影像可能受云遮挡）。</p></blockquote><p><b>GAN的组成</b></p><blockquote><p>GAN相当于是由两个网络组成，一个是生成网络，一个是判别网络，生成网络相当于生产员，是用来将输入的随机噪声（原材料）生成一幅图像X（产品），判别网络相当于质检员，是将真实图像Y（产品标准）与生成图像X作比较，给出图像X是真还是假，通过她的判断，网络会不断优化，直至我们生成的图像（产品）接近于真实图像（接近于产品标准）。</p></blockquote><h2 id="用处"><a href="#用处" class="headerlink" title="用处"></a>用处</h2><p>GAN应用领域非常之广，不乏图像生成，图像转换（卫星图像→谷歌地图、给图像加滤镜、换脸、换衣服、素描→彩色图片），图像超分辨（修复一些比较老的影视剧）以及图像修复等等，但我学习的只涉及到图像生成领域，所以关于GAN的介绍也仅仅局限于图像生成。</p><p>GAN 在图像生成上的应用又可分为以下几种：图像合成、文本到图像、图像到图像、视频。图像生成是研究最多的，并且该领域的研究已经证明了在图像合成中使用 GAN 的巨大潜力。</p><h2 id="GAN发展"><a href="#GAN发展" class="headerlink" title="GAN发展"></a>GAN发展</h2><p>GAN如此之优秀，值得我们去探究了解她的发展。下面主要是对GAN经典模型的介绍，其他模型也大多是基于这些经典模型的改进。</p><p>2014年Goodfellow等人提出了GAN模型，原理如图1所示。之后Conditional GAN（CGAN）被Mizra等人提出，该模型将标签引入到网络中，使得生成的图像可以按标签的顺序罗列，解决了传统GAN生成顺序混乱的问题，原理如图2所示。</p><div align="center"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-76a6a1d99af14b6785434af91cb77014_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1657697403&amp;t=359fbd3690280aef59550b9a3823347c"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 GAN基本框架</div></div><br><div align="center"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fwww.icode9.com%2Fi%2Fll%2F%3Fi%3D20210306153717338.png%3F%2Ctype_ZmFuZ3poZW5naGVpdGk%2Cshadow_10%2Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3OTM3ODQ3%2Csize_16%2Ccolor_FFFFFF%2Ct_70%23pic_center&amp;refer=http%3A%2F%2Fwww.icode9.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1657697365&amp;t=f4ce77837538c79656071de725512abf"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 CGAN基本框架</div></div><p>2016年Radford提出了DCGAN，将深度卷积模块引入到GAN中，提高了GAN网络生成模型的性能，从此卷积模块也成为了GAN网络的优化方式之一。在这一年InfoGAN也被提出，这篇文章主要加入了隐含向量，可解释隐含向量是改变字体的大小粗细和倾斜度。<br><br></p><div align="center"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fs1.ax1x.com%2F2020%2F06%2F04%2FtB3BAf.md.png&amp;refer=http%3A%2F%2Fs1.ax1x.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1657697476&amp;t=3d4f1ae0e5826d29d832c52bdc0402d6"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 DCGAN基本框架</div></div><br>2017年Pix2pix被Isola提出，一个以CGAN为基础，用于图像翻译（Image Translation）的通用框架，它实现了模型结构和损失函数的通用化,CycleGAN与其类似，它与DiscoGAN、DualGAN网络结构也完全类似。之后WGAN（Wasserstein GAN）被提出，传统的GAN的使用的是KL散度或JS散度计算真假图像分布，所存在的问题是mode collapse，通俗的讲就是epoch越大，生成的图像会趋于某一个分布，而将Wasserstein距离的优势是计算两个分布的最小代价。随之WGAN-GP问世，该模型将gradient penalty (GP)引入，主要解决WGAN模型建模能力弱化，以及梯度爆炸或消失的问题。当然，在今年也提出了用的较多的GAN模型评价函数FID（Fréchet Inception 距离）。<p>从2018年起，GAN更加多样化，比较有代表性的比如StarGAN，它是将一个域的图像转换为目标域的多种图像，并支持多个目标域，简单说就是将原图像变换样式/风格style。例如，可根据人的性别设置图像域domain，在这种情况下，风格样式包括妆容类别、胡须和发型等。但这些基本上仍然是基于InfoGAN的思路，加入更多的隐含向量。</p><p>2019年BigGAN,StyleGAN在图像生成领域应用还比较多，BigGAN顾名思义，就是大，体现在在训练中 Batch 采用了很大的 Batch，已经达到了 2048，在卷积的通道上也是变大了，还有就是网络的参数变多了，据计算，在 2048 的 Batch 下整个网络的参数达到了接近 16 亿。StyleGAN是一种无监督式的自动学习方法，她对图像的高层语义属性做一定解耦分离，例如人脸图像的姿势和身份、所生成图像的随机变化如雀斑和头发等，但是，这些所解析的特征向量并不固定，也存在有些特征向量无法解释的问题。</p><p>2020年各大顶刊的文章对于GAN的变型数不胜数，主要基于了不同的需求，比如PSGAN将妆容和姿势进行风格变换，还引入了注意力机制。MISC针对多种背景的、多条件人像合成，提出了MISC，用于条件图像生成和图像组合。对于条件图像生成，利用条件间相关性来改进现有的条件注入机制condition injection mechanisms。</p><p>2021年与2022年的文章也更多，比如文本转图像，改进注意力机制，将transformer加入到GAN中，但总体GAN模型框架并没有太大的改变。在此不再罗列模型名称（PS：每个人的模型名称都是千差万别，实在是怪我没有能力全记住，哈哈哈）</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上就是GAN按时间顺序的发展历程，各有优缺点，也适应着各种不同的领域，总的来说，有网络结构的改进，比如加入标签、隐含向量、注意力、VAE等等；还有损失函数的优化，比如KL、JS、wasserstein距离等等。这就使得GAN可以做有监督的图像生成也可以做无监督的图像生成，我们需要根据不同的需求去测试不同网络的效果。从下一节开始，我们将逐一介绍以上经典网络，以及如何实现。</p><h3 id="以上是GAN一些基础知识，由于我了解也不够深入，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是GAN一些基础知识，由于我了解也不够深入，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是GAN一些基础知识，由于我了解也不够深入，如有错误，欢迎指出，谢谢您！！！"></a>以上是GAN一些基础知识，由于我了解也不够深入，如有错误，欢迎指出，谢谢您！！！</h3>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>No.3 FID环境搭建</title>
      <link href="/2022/06/05/fifthblog/"/>
      <url>/2022/06/05/fifthblog/</url>
      
        <content type="html"><![CDATA[<h1 id="NO-3-FID环境搭建遇到的问题"><a href="#NO-3-FID环境搭建遇到的问题" class="headerlink" title="NO.3 FID环境搭建遇到的问题"></a>NO.3 FID环境搭建遇到的问题</h1><h2 id="参数默认值设置"><a href="#参数默认值设置" class="headerlink" title="参数默认值设置"></a>参数默认值设置</h2><p>加载参数时出现了下面这个错误，错误原因是”path”参数是必须的</p><blockquote><p>usage: fid_score.py [-h] [–batch-size BATCH_SIZE] [–num-workers NUM_WORKERS] [–device DEVICE]<br>                    [–dims {64,192,768,2048}]<br>                    path path<br>fid_score.py: error: the following arguments are required: path<br>An exception has occurred, use %tb to see the full traceback.</p></blockquote><p><b> 解决方法：</b><br>虽然代码中存在”path”参数，但需要在”path”加上”–”,才可以设置该参数的默认值</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--path'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> nargs<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>default<span class="token operator">=</span><span class="token string">"./data/"</span><span class="token punctuation">,</span>                    <span class="token builtin">help</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'Paths to the generated images or '</span>                          <span class="token string">'to .npz statistic files'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="没有属性sched-getaffinity"><a href="#没有属性sched-getaffinity" class="headerlink" title="没有属性sched_getaffinity"></a>没有属性sched_getaffinity</h2><p>OS模块没有sched_getaffinity属性，具体报错信息：</p><blockquote><p>AttributeError: module ‘os’ has no attribute ‘sched_getaffinity’</p></blockquote><p>os.sched_getaffinity()Python中的method方法用于获取可在其上运行具有指定进程ID的进程的CPU组<br>此方法仅在某些LIUNX平台上可用。</p><p><b> 解决方法：</b></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">num_workers <span class="token operator">=</span> <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="CUDA错误：no-kernel-image"><a href="#CUDA错误：no-kernel-image" class="headerlink" title="CUDA错误：no kernel image"></a>CUDA错误：no kernel image</h2><p>具体错误信息：</p><blockquote><p>CUDA error: no kernel image is available for execution on the device</p></blockquote><p>这个错误网上主要有两种解决办法，</p><ol><li>GPU与CUDA版本不兼容<br><b> 解决方法：</b><br>CUDA官网查看，python、cuda、torch的对应版本情况<br>下面这个链接可以直接查看版本对应号，找到之后，去重新安装正确的版本<br><a href="https://blog.csdn.net/weixin_45564943/article/details/121688734">https://blog.csdn.net/weixin_45564943/article/details/121688734</a></li><li>电脑配置不行<br>重新换个配置高的电脑</li><li>编译器的问题<br>以上两种方法都没有解决我的问题，实在没有找到解决方法，因为这个问题是在spyder中报的错，所以就尝试将spyder换成了pycharm，运行之后，发现没有报错，具体为什么，我也搞不明白。。。</li></ol><p><b> 补充: </b></p><ol><li><p>如果你的问题是第一种，但你可能无法下载指定版本的torch,这时需要你自己编译torch，所以下面这个博主帮大家解决了如何编译Pytorch源码的问题<br><a href="https://blog.csdn.net/qq_43051923/article/details/108393510">https://blog.csdn.net/qq_43051923/article/details/108393510</a></p></li><li><p>如何查Windows下的CUDA版本？<br> <a href="https://blog.csdn.net/qq_40447251/article/details/95861447">https://blog.csdn.net/qq_40447251/article/details/95861447</a></p></li></ol><h3 id="以上是我计算FID搭建环境时遇到的问题，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是我计算FID搭建环境时遇到的问题，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是我计算FID搭建环境时遇到的问题，如有错误，欢迎指出，谢谢您！！！"></a>以上是我计算FID搭建环境时遇到的问题，如有错误，欢迎指出，谢谢您！！！</h3>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> python </tag>
            
            <tag> FID </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>No.2 GAN的实现</title>
      <link href="/2022/05/31/sixblog/"/>
      <url>/2022/05/31/sixblog/</url>
      
        <content type="html"><![CDATA[<h1 id="NO-2-GAN的实现"><a href="#NO-2-GAN的实现" class="headerlink" title="NO.2 GAN的实现"></a>NO.2 GAN的实现</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote><p>这是GAN相关内容的第二节介绍，考虑到大多数的资料可能原理是原理，代码是代码，我希望我写的东西，可以将代码与原理尽量一一对应，因为当我们明白代码是如何实现这些数学理论后，我们就可以去改进、完善模型。<br>但介绍原理我并不擅长，只能利用我薄弱的数学基础，以我能理解的方式去介绍，所以难免可能会有错误，如果你有幸看到我这篇文章又很费心碰巧发现了错误，恳请批评指正~</p></blockquote><p>为了将原理与代码对应，我们主要分两部分介绍：前向传播与后向传播。在GAN中前向传播包括了生成网络与判别网络两部分，后向传播是损失函数。</p><h2 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h2><p> 初始化，随机产生一组变量，此时初始化的G与D没有任何作用。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">valid <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>随机生成一组分布z，将z输入到G得到一组假图（fake images）即x’ = G(z)，在整个图像生成中，G并没有输入真实图片x，它也不在乎真实图片x长什么样，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#随机噪声</span>gen_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">)</span>    <span class="token comment">#生成器生成fake图像</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>取一组图片x，输入到判别器计算D(x)，对于判别器会接收真实图像，也会接收G生成的fake图，接收真图代码如下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">real_imgs <span class="token operator">=</span> Variable<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">)</span>discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span>    <span class="token comment">#判别器</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>以上generator与discriminator即为GAN搭建的网络模型，代码在最后给出。</p><h2 id="后向传播"><a href="#后向传播" class="headerlink" title="后向传播"></a>后向传播</h2><p>因为判别器D与生成器G是两个不同的网络模型，所以是分别计算loss值后进行反向传播。对于G，它的目标是让D误以为x’是真实图片，因此G的损失函数可以是D(x’)和1之间的差距，这个差距越小，表明在D看来x’越真实。按照loss减小的方向，调整G的每一个参数，便完成了G的一次优化。我们需要固定判别器优化生成器，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">g_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>  <span class="token comment">#计算loss</span>g_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#反向传播</span>optimizer_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#优化参数</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>对于D，损失函数包括两方面：第一是真图计算的D(x)应当比较大，例如和1尽可能接近；第二是fake图x’对应的D(x’)应当比较小，例如和0尽可能接近。同理以loss函数减小的方向，调整D的每一个参数实现对D优化。我们需要固定生成器优化判别器，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">real_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>fake_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fake<span class="token punctuation">)</span>d_loss <span class="token operator">=</span> <span class="token punctuation">(</span>real_loss <span class="token operator">+</span> fake_loss<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>d_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer_D<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ok,G和D的优化都用到了adversarial_loss，那这个loss代码如何实现的呢？</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">adversarial_loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其实就是使用了BCELoss（交叉熵），然后BCELoss的公式如下图</p><div align="center"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fwww.pianshen.com%2Fimages%2F127%2F0dbe652bb1b3227e59e62749290e6a57.png&amp;refer=http%3A%2F%2Fwww.pianshen.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1657812535&amp;t=d85047d914af232e2bf8823350ebce27"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 BCElOSS</div></div><br><p>ok,而论文给的loss计算公式如下，发现与BCELoss的公式还是有差别的，发现第一项少了BCE公式的后半部分，第二项少了BCE公式的前半部分。注意第一项的E x ∼ p r ( x ) E的下标表示x来自真实样本，所以在BCE公式的yn = 1，所以BCE公式的后半部分为0，第二项同理也为0，我们也可以看到代码中D也是分别求了两个Loss值。至于生成器的公式同理，在此也没有再赘述。</p><div align="center"><img src="https://img-blog.csdnimg.cn/20191213145817665.png"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 原文中的Loss计算公式</div></div><br><h2 id="网络模型代码"><a href="#网络模型代码" class="headerlink" title="网络模型代码"></a>网络模型代码</h2><p>前向传播我们没有具体给出G与D的模型代码，在此我们给出模型代码与训练优化的实现代码，但是在此没有给出如何加载数据集的程序，后面我们会介绍如何用torch构建无标签和有标签的数据集：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Generator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">block</span><span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>                layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>out_feat<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> layers        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>        img <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        img <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>img_shape<span class="token punctuation">)</span>        <span class="token keyword">return</span> img<span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        img_flat <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        validity <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>img_flat<span class="token punctuation">)</span>        <span class="token keyword">return</span> validity<span class="token comment"># Loss function</span>adversarial_loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># Initialize generator and discriminator</span>generator <span class="token operator">=</span> Generator<span class="token punctuation">(</span><span class="token punctuation">)</span>discriminator <span class="token operator">=</span> Discriminator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> cuda<span class="token punctuation">:</span>    generator<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    discriminator<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    adversarial_loss<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># Configure data loader</span>img_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    <span class="token comment"># transforms.ToPILImage(),</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># (x-mean) / std</span><span class="token punctuation">]</span><span class="token punctuation">)</span>optimizer_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>generator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span>optimizer_D <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span>Tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>FloatTensor <span class="token keyword">if</span> cuda <span class="token keyword">else</span> torch<span class="token punctuation">.</span>FloatTensor <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> img <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>            imgs <span class="token operator">=</span> img                        valid <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>            fake <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>            <span class="token comment"># Configure input</span>            real_imgs <span class="token operator">=</span> Variable<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment"># -----------------</span>            <span class="token comment">#  Train Generator</span>            <span class="token comment"># -----------------</span>            optimizer_G<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># Sample noise as generator input</span>            z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment"># Generate a batch of images</span>            gen_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">)</span>            <span class="token comment"># Loss measures generator's ability to fool the discriminator</span>            g_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>            g_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># ---------------------</span>            <span class="token comment">#  Train Discriminator</span>            <span class="token comment"># ---------------------</span>            optimizer_D<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># Measure discriminator's ability to classify real from generated samples</span>            real_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>            fake_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fake<span class="token punctuation">)</span>            d_loss <span class="token operator">=</span> <span class="token punctuation">(</span>real_loss <span class="token operator">+</span> fake_loss<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>            d_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer_D<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>                <span class="token string">"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"</span>                <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>n_epochs<span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> d_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> g_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token punctuation">)</span>            batches_done <span class="token operator">=</span> epoch <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span> <span class="token operator">+</span> i            <span class="token keyword">if</span> <span class="token punctuation">(</span>batches_done <span class="token operator">%</span> opt<span class="token punctuation">.</span>sample_interval <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> epoch <span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                save_image<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> savename<span class="token operator">+</span>save_filename<span class="token operator">+</span><span class="token string">'_'</span><span class="token operator">+</span><span class="token string">"%d.png"</span> <span class="token operator">%</span> batches_done<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="以上是GAN的第二节介绍，主要介绍了原理与实现，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是GAN的第二节介绍，主要介绍了原理与实现，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是GAN的第二节介绍，主要介绍了原理与实现，如有错误，欢迎指出，谢谢您！！！"></a>以上是GAN的第二节介绍，主要介绍了原理与实现，如有错误，欢迎指出，谢谢您！！！</h3>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python 爬虫</title>
      <link href="/2022/05/28/thirblog/"/>
      <url>/2022/05/28/thirblog/</url>
      
        <content type="html"><![CDATA[<h1 id="用python从mou网页中简单抓取mou信息"><a href="#用python从mou网页中简单抓取mou信息" class="headerlink" title="用python从mou网页中简单抓取mou信息"></a>用python从mou网页中简单抓取mou信息</h1><blockquote><p>爬虫并不专业，但写这篇是因为昨天蒋总提到爬虫，担心离职前没时间交流这个事，所以先写个blog，以防万一哪天你（您）又问我了，我不在公司咋整？（后半句纯粹为自己写这篇找的理由，哈哈哈 ）</p></blockquote><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>某知名襄阳富二代小朱想了解一下竞争对手，网站上发布了考试信息，我们准备帮他找一下和他考一个专业的学生有多少个，考试名单如下：</p><br><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2psh6l8j30wv0o446u.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 需要爬虫的信息</div></div><br><!--<div align="center"><img src="./thirblog/1.png"/></div>--><h2 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h2><p>打开cmd运行如下命令，安装两个包requests、bs4</p><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">pip install requestspip install bs4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果使用pip安装bs4报错，可以采用本地安装方式：</p><p>1、下载bs4包到本地并解压（记住路径）：<a href="https://www.crummy.com/software/BeautifulSoup/bs4/download/">https://www.crummy.com/software/BeautifulSoup/bs4/download/</a><br>2、用cmd定位到下载的bs4包：beautifulsoup4-4.11.1</p><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">cd E:\Program Files (x86)\beautifulsoup4-4.11.1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3、本地安装bs4，使用命令：</p><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">python setup.py install<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="爬取网页内容"><a href="#爬取网页内容" class="headerlink" title="爬取网页内容"></a>爬取网页内容</h2><p>ok，准备工作完成，爬取网页信息：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">url <span class="token operator">=</span> <span class="token string">'http://jw.hbuas.edu.cn/info/1061/2393.htm'</span>  <span class="token comment">#网址</span>response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>  <span class="token comment"># 获取该网址的信息</span>response<span class="token punctuation">.</span>encoding<span class="token operator">=</span>response<span class="token punctuation">.</span>apparent_encoding  <span class="token comment">#这一步是判断网页的解码格式，因为网页的编码方式不同</span>html <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">,</span><span class="token string">'lxml'</span><span class="token punctuation">)</span> <span class="token comment">#使用lxml解析器，对网页信息进行解析</span>content<span class="token operator">=</span>html<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#vsb_content &gt; div &gt; div &gt; div'</span><span class="token punctuation">)</span><span class="token comment">#将复制好的选择器信息放进select方法中，将获取到的内容作为tag形式放入一个列表中</span><span class="token comment">#这一步很关键，取决你的网页形式，需要F12打开网页源码，去查看你想要的内容在哪个div下</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果打印的结果不是0，说明已经成功抓取你想要的信息</p><h2 id="保存结果"><a href="#保存结果" class="headerlink" title="保存结果"></a>保存结果</h2><p>我们将抓取的信息保存到了txt文档中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">filename <span class="token operator">=</span> <span class="token string">"1.txt"</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"1.txt"</span><span class="token punctuation">,</span><span class="token string">"w"</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">:</span>    s <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>content<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>s<span class="token punctuation">)</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"保存文件成功"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们抓取的信息如下：</p><br><div align="center"><img src="https://wx2.sinaimg.cn/mw2000/006b3B1mly1h3h2psld3yj30ly0hhjtl.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 爬虫结果</div></div><br><!--<div align="center"><img src="./thirblog/2.png"/></div>--><h2 id="整理结果"><a href="#整理结果" class="headerlink" title="整理结果"></a>整理结果</h2><br><div align="center"><img src="https://wx1.sinaimg.cn/mw2000/006b3B1mly1h3h2pssdr6j30n30atn55.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 统计结果</div></div><br><!--<div align="center"><img src="./thirblog/3.png"/></div>--><p>在EXCEL打开后，我们看到有315个学生考地理科学专业，听小朱说招90多个，离考试还有二十多天，在此也默默祝福小朱金榜题名！！！</p><p>最后，我用jieba对这组数据尝试做了词云分析，这些数据也很有趣，但我没做详细分析，比如考生涉及的城市武汉，襄阳较多；除汉族考生外回族考生也不少；<br>考生姓氏张、刘等较多；报考旅游、地理科学、学前教育、机械等专业考生较多，或许是该校优势专业，等等。。。</p><br><div align="center"><img src="https://wx4.sinaimg.cn/mw2000/006b3B1mly1h3h2pszm52j311i0ku11a.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图4 词云分析</div></div><br><!--<div align="center"><img src="./thirblog/4.png"/></div>--><h4 id="简单的一个从网页抓取信息的例子就完成了，如有错误，欢迎指出，谢谢您！！！"><a href="#简单的一个从网页抓取信息的例子就完成了，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="简单的一个从网页抓取信息的例子就完成了，如有错误，欢迎指出，谢谢您！！！"></a>简单的一个从网页抓取信息的例子就完成了，如有错误，欢迎指出，谢谢您！！！</h4>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo部署</title>
      <link href="/2022/05/22/secblog/"/>
      <url>/2022/05/22/secblog/</url>
      
        <content type="html"><![CDATA[<h1 id="hexo部署"><a href="#hexo部署" class="headerlink" title="hexo部署"></a>hexo部署</h1><blockquote><p>上一篇解决了hexo安装的问题，这一篇简单介绍如何进行hexo搭建一个简单博客</p></blockquote><h2 id="下载主题"><a href="#下载主题" class="headerlink" title="下载主题"></a>下载主题</h2><p>hexo官方主题下载地址：<a href="https://hexo.io/themes/">https://hexo.io/themes/</a><br>这里面挑选适合的主题，比如下载下面这个主题：<a href="https://github.com/JoeyBling/hexo-theme-yilia-plus">https://github.com/JoeyBling/hexo-theme-yilia-plus</a><br>在根目录下，右键鼠标打开bash<br><br></p><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2p9okqrj30ko0b70td.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 hexo打开</div></div><br><!--![](./secblog/bash.png)--><p>运行如下命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token builtin class-name">cd</span> theme$ <span class="token function">git</span> clone --depth<span class="token operator">=</span><span class="token number">1</span> https://github.com/JoeyBling/hexo-theme-yilia-plus.git ./yilia-plus<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>修改hexo根目录下的 _config.yml中，修改theme: yilia-plus</p><h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2><p>运行如下命令</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token builtin class-name">cd</span> themes/yilia-plus$ <span class="token function">git</span> pull<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="配置config"><a href="#配置config" class="headerlink" title="配置config"></a>配置config</h2><p>在_config.yml中配置自己喜欢的样式即可，github可以查看每个主题的config的内容，不再赘述。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>同样在根目录下打开bash，运行如下命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo clean$ hexo generate$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>当然部署会遇到一些问题。比如： Failed to connect to github.com port 443: Timed out</p><br><div align="center"><img src="https://wx1.sinaimg.cn/mw2000/006b3B1mly1h3h2p9rw0lj30jo073wjt.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 部署问题</div></div><br><!--![](./secblog/hexod.png)--><p>出现这种问题很正常，这是本地部署，会存在网络的问题，可以打开（关闭）翻墙软件，多次尝试部署，成功部署会显示：</p><br><div align="center"><img src="https://wx2.sinaimg.cn/mw2000/006b3B1mly1h3h2p9w66tj30k706jn2s.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 上传成功</div></div><br><!--![](./secblog/hexosuc.png)--><p>如果这种问题一直未能解决，可以选择Hexo Github Action、vercel 部署等方式。</p><h3 id="以上是部署hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是部署hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是部署hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！"></a>以上是部署hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！</h3>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo安装问题</title>
      <link href="/2022/05/16/firstblog/"/>
      <url>/2022/05/16/firstblog/</url>
      
        <content type="html"><![CDATA[<h1 id="Windows下使用npm安装hexo报错"><a href="#Windows下使用npm安装hexo报错" class="headerlink" title="Windows下使用npm安装hexo报错"></a>Windows下使用npm安装hexo报错</h1><blockquote><p>本篇共解决三个问题：ERR；npm update； hexo command not found</p></blockquote><h2 id="ERR错误"><a href="#ERR错误" class="headerlink" title="ERR错误"></a>ERR错误</h2><p>在安装npm时，遇到第一个问题是一连串的ERR错误，网上主要有两种解决方法，如果you遇到同样问题，可以先尝试如下</p><p><b> 解决方法：</b></p><ul><li>删除C:\Users{user}下的.npmrc文件</li><li>运行命令：<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">npm</span> cache clean –force<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>但我尝试两种方法后，安装npm，仍然还存在以下问题：</li></ul><br><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2oljl6yj30pv0d1k90.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图1 ERR错误</div></div><br><!-- ![](./firstblog/hexo1.png)--><p><b> 解决方法：</b></p><p>搞了好久，检查之后，发现是打开了翻墙软件，所以这个报错有可能是pip打不开需要访问的地址。关掉后，问题解决！！！但又出现下一个问题。</p><h2 id="npm更新问题"><a href="#npm更新问题" class="headerlink" title="npm更新问题"></a>npm更新问题</h2><!-- ![](./firstblog/hexo2.png)--><br><div align="center"><img src="https://wx2.sinaimg.cn/mw2000/006b3B1mly1h3h2olppxbj30ju07ggpt.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图2 npm更新</div></div><br><p>提示Run npm install -g <a href="mailto:npm@8.10.0">npm@8.10.0</a> to update<br>运行命令，对npm先升级，再安装hexo</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">npm</span> <span class="token function">install</span> -g <span class="token function">npm</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="hexo已安装，但找不到该命令"><a href="#hexo已安装，但找不到该命令" class="headerlink" title="hexo已安装，但找不到该命令"></a>hexo已安装，但找不到该命令</h2><p>运行hexo -v查看安装版本时，又出现hexo不是内部命令，或者出现“bash: hexo: command not found”提示</p><!-- <div align="center"><img src="./firstblog/hexo3.png"/></div>--><br><div align="center"><img src="https://wx3.sinaimg.cn/mw2000/006b3B1mly1h3h2oltd0oj30d302e3zc.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图3 hexo命令</div></div><br><p><b> 解决方法：</b><br>找到 C:\Users\Administrator\AppData\Roaming\npm\node_modules\hexo\bin\，将此目录添加到path环境变量中<br>重新打开命令窗口，成功。</p><!-- <div align="center"><img src="./firstblog/hexo4.png"/></div>--><br><div align="center"><img src="https://wx4.sinaimg.cn/mw2000/006b3B1mly1h3h2oly5hyj306l08ygnz.jpg"><br><div style="color:orange;boder-bottom:1px solid #d9d9d9;display: inline-block;color:#999;padding:2px;">图4 hexo成功安装</div></div><br><h3 id="以上是我安装hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！"><a href="#以上是我安装hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！" class="headerlink" title="以上是我安装hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！"></a>以上是我安装hexo遇到的一些小问题，如有错误，欢迎指出，谢谢您！！！</h3>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> npm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/05/12/hello-world/"/>
      <url>/2022/05/12/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
